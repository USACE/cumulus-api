{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This site contains the project documentation for the cumulus_geoproc Table Of Contents Cumulus Geoproc Geoprocess HRRR SNODAS Processors Utils/boto Utils/capi Utils/cgdal","title":"Home"},{"location":"#table-of-contents","text":"Cumulus Geoproc Geoprocess HRRR SNODAS Processors Utils/boto Utils/capi Utils/cgdal","title":"Table Of Contents"},{"location":"cumulus_geoproc/","text":"Initialize package package_logger Bases: logging . Logger Package logger extending logging.Logger Parameters: Name Type Description Default logging Logger Logger object required Source code in cumulus_geoproc/__init__.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class package_logger ( logging . Logger ): \"\"\"Package logger extending logging.Logger Parameters ---------- logging : Logger Logger object \"\"\" def __init__ ( self ): super () . __init__ ( __package__ ) self . log_level = \"info\" formatter = logging . Formatter ( \"[ %(asctime)s . %(msecs)03d ] \" + \"{ %(name)s : %(funcName)s } - %(levelname)-s - %(message)s \" , \"%Y-%m- %d T%H:%M:%S\" , ) ch = logging . StreamHandler () ch . setFormatter ( formatter ) self . addHandler ( ch ) @property def log_level ( self ): return logging . _levelToName [ self . level ] @log_level . setter def log_level ( self , level ): level = logging . _nameToLevel [ level . upper ()] if isinstance ( level , str ) else level self . setLevel ( level )","title":"Cumulus geoproc"},{"location":"cumulus_geoproc/#cumulus_geoproc.package_logger","text":"Bases: logging . Logger Package logger extending logging.Logger Parameters: Name Type Description Default logging Logger Logger object required Source code in cumulus_geoproc/__init__.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class package_logger ( logging . Logger ): \"\"\"Package logger extending logging.Logger Parameters ---------- logging : Logger Logger object \"\"\" def __init__ ( self ): super () . __init__ ( __package__ ) self . log_level = \"info\" formatter = logging . Formatter ( \"[ %(asctime)s . %(msecs)03d ] \" + \"{ %(name)s : %(funcName)s } - %(levelname)-s - %(message)s \" , \"%Y-%m- %d T%H:%M:%S\" , ) ch = logging . StreamHandler () ch . setFormatter ( formatter ) self . addHandler ( ch ) @property def log_level ( self ): return logging . _levelToName [ self . level ] @log_level . setter def log_level ( self , level ): level = logging . _nameToLevel [ level . upper ()] if isinstance ( level , str ) else level self . setLevel ( level )","title":"package_logger"},{"location":"geoprocess/geoprocess/","text":"Geoprocess init handle the messages coming from the worker thread handle_message ( geoprocess , GeoCfg , dst ) Handle the message from SQS determining what to do with it Geo processing is either 'snodas-interpolate' or 'incoming-file-to-cogs' Return a list of dictionary objects defining what was created and needs to be uploaded to S3 and notify Cumulus DB. Parameters: Name Type Description Default geoprocess str Geoprocess name required GeoCfg namedtuple namedtuple with geoprocess config from payload required dst str FQP to temporary directory created/downloaded files go required Returns: Type Description list [ dict ] list of dictionary objects Source code in cumulus_geoproc/geoprocess/handler.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def handle_message ( geoprocess : str , GeoCfg : namedtuple , dst : str ): \"\"\"Handle the message from SQS determining what to do with it Geo processing is either 'snodas-interpolate' or 'incoming-file-to-cogs' Return a list of dictionary objects defining what was created and needs to be uploaded to S3 and notify Cumulus DB. Parameters ---------- geoprocess : str Geoprocess name GeoCfg : namedtuple namedtuple with geoprocess config from payload dst : str FQP to temporary directory created/downloaded files go Returns ------- list[dict] list of dictionary objects \"\"\" proc_list = [] if geoprocess == \"snodas-interpolate\" : logger . debug ( f \"Geoprocess ' { geoprocess } ' working on ' { GeoCfg . datetime } '\" ) proc_list = asyncio . run ( interpolate . snodas ( GeoCfg , dst = dst , ) ) elif geoprocess == \"incoming-file-to-cogs\" : # process and get resulting dictionary object defining the new grid # add acquirable id to each object in the list if src := boto . s3_download_file ( bucket = GeoCfg . bucket , key = GeoCfg . key ): proc_list = geo_proc ( plugin = GeoCfg . acquirable_slug , src = src , acquirable = GeoCfg . acquirable_slug , ) return proc_list upload_notify ( notices , bucket ) Upload processed products and POST notification Parameters: Name Type Description Default notices list list of successful uploads to S3 required bucket str S3 bucket required Returns: Type Description List List of successful uploads and POST notifications Source code in cumulus_geoproc/geoprocess/handler.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 def upload_notify ( notices : list , bucket : str ): \"\"\"Upload processed products and POST notification Parameters ---------- notices : list list of successful uploads to S3 bucket : str S3 bucket Returns ------- List List of successful uploads and POST notifications \"\"\" responses = [] payload = [] # upload for notice in notices : # try to upload and continue if it doesn't returning only # what was successfully uploaded logger . debug ( f \"Upload Notice from Notices: { notice =} \" ) try : # try to upload to S3 file = notice [ \"file\" ] filename = os . path . basename ( file ) key = \"/\" . join ([ CUMULUS_PRODUCTS_BASEKEY , notice [ \"filetype\" ], filename ]) logger . debug ( f \"Notice key: { key } \" ) # upload the file to S3 if boto . s3_upload_file ( file , bucket , key ): logger . debug ( f \"S3 Upload: { file } -> { bucket } / { key } \" ) # If successful on upload, notify cumulus, but # switch file to the key first notice [ \"file\" ] = key responses . append ({ \"key\" : key }) payload . append ( notice ) logger . debug ( f \"Append Response: { responses [ - 1 ] } \" ) except ( KeyError , ClientError , Exception ) as ex : logger . warning ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue # notify if len ( payload ) > 0 : cumulus_api = capi . CumulusAPI ( CUMULUS_API_URL , HTTP2 ) cumulus_api . endpoint = \"productfiles\" cumulus_api . query = { \"key\" : APPLICATION_KEY } logger . debug ( f \"Payload to POST: { payload } \" ) resp = asyncio . run ( cumulus_api . post_ ( cumulus_api . url , payload = payload )) responses . append ({ \"upload\" : resp }) return responses","title":"Geoprocess"},{"location":"geoprocess/geoprocess/#cumulus_geoproc.geoprocess.handler.handle_message","text":"Handle the message from SQS determining what to do with it Geo processing is either 'snodas-interpolate' or 'incoming-file-to-cogs' Return a list of dictionary objects defining what was created and needs to be uploaded to S3 and notify Cumulus DB. Parameters: Name Type Description Default geoprocess str Geoprocess name required GeoCfg namedtuple namedtuple with geoprocess config from payload required dst str FQP to temporary directory created/downloaded files go required Returns: Type Description list [ dict ] list of dictionary objects Source code in cumulus_geoproc/geoprocess/handler.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def handle_message ( geoprocess : str , GeoCfg : namedtuple , dst : str ): \"\"\"Handle the message from SQS determining what to do with it Geo processing is either 'snodas-interpolate' or 'incoming-file-to-cogs' Return a list of dictionary objects defining what was created and needs to be uploaded to S3 and notify Cumulus DB. Parameters ---------- geoprocess : str Geoprocess name GeoCfg : namedtuple namedtuple with geoprocess config from payload dst : str FQP to temporary directory created/downloaded files go Returns ------- list[dict] list of dictionary objects \"\"\" proc_list = [] if geoprocess == \"snodas-interpolate\" : logger . debug ( f \"Geoprocess ' { geoprocess } ' working on ' { GeoCfg . datetime } '\" ) proc_list = asyncio . run ( interpolate . snodas ( GeoCfg , dst = dst , ) ) elif geoprocess == \"incoming-file-to-cogs\" : # process and get resulting dictionary object defining the new grid # add acquirable id to each object in the list if src := boto . s3_download_file ( bucket = GeoCfg . bucket , key = GeoCfg . key ): proc_list = geo_proc ( plugin = GeoCfg . acquirable_slug , src = src , acquirable = GeoCfg . acquirable_slug , ) return proc_list","title":"handle_message()"},{"location":"geoprocess/geoprocess/#cumulus_geoproc.geoprocess.handler.upload_notify","text":"Upload processed products and POST notification Parameters: Name Type Description Default notices list list of successful uploads to S3 required bucket str S3 bucket required Returns: Type Description List List of successful uploads and POST notifications Source code in cumulus_geoproc/geoprocess/handler.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 def upload_notify ( notices : list , bucket : str ): \"\"\"Upload processed products and POST notification Parameters ---------- notices : list list of successful uploads to S3 bucket : str S3 bucket Returns ------- List List of successful uploads and POST notifications \"\"\" responses = [] payload = [] # upload for notice in notices : # try to upload and continue if it doesn't returning only # what was successfully uploaded logger . debug ( f \"Upload Notice from Notices: { notice =} \" ) try : # try to upload to S3 file = notice [ \"file\" ] filename = os . path . basename ( file ) key = \"/\" . join ([ CUMULUS_PRODUCTS_BASEKEY , notice [ \"filetype\" ], filename ]) logger . debug ( f \"Notice key: { key } \" ) # upload the file to S3 if boto . s3_upload_file ( file , bucket , key ): logger . debug ( f \"S3 Upload: { file } -> { bucket } / { key } \" ) # If successful on upload, notify cumulus, but # switch file to the key first notice [ \"file\" ] = key responses . append ({ \"key\" : key }) payload . append ( notice ) logger . debug ( f \"Append Response: { responses [ - 1 ] } \" ) except ( KeyError , ClientError , Exception ) as ex : logger . warning ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue # notify if len ( payload ) > 0 : cumulus_api = capi . CumulusAPI ( CUMULUS_API_URL , HTTP2 ) cumulus_api . endpoint = \"productfiles\" cumulus_api . query = { \"key\" : APPLICATION_KEY } logger . debug ( f \"Payload to POST: { payload } \" ) resp = asyncio . run ( cumulus_api . post_ ( cumulus_api . url , payload = payload )) responses . append ({ \"upload\" : resp }) return responses","title":"upload_notify()"},{"location":"geoprocess/hrrr/","text":"High Resolution Rapid Refresh (HRRR) utilities HrrrIdx HRRR index (idx) files describe all elements in the grib2 file This class provides methods to parse lines from idx files and return a band number. Logic to determine if the resulting parse values are done outside this class. Source code in cumulus_geoproc/geoprocess/hrrr/__init__.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class HrrrIdx : \"\"\"HRRR index (idx) files describe all elements in the grib2 file This class provides methods to parse lines from idx files and return a band number. Logic to determine if the resulting parse values are done outside this class. \"\"\" def __init__ ( self ): self . el = None self . sep_ = \":\" self . band = None self . cycle_dt = None self . desc = None self . fcst_hr = None self . sdf = \"%Y%m %d %H%M\" self . fcst_pattern = re . compile ( r \"\\d+-?\\d+\" ) def __repr__ ( self ): return f \" { __class__ . __name__ } ()\" @property def element ( self ): return self . el def sep ( self , s : str ): self . sep = s def linex ( self , line : str ): try : parts = line . split ( \":\" ) self . band = parts [ 0 ] self . cycle_dt = parts [ 2 ][ 2 :] self . el = parts [ 3 ] self . desc = parts [ 4 ] self . fcst_hr = parts [ 5 ] except ( ValueError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) @property def raster_band ( self ): try : return int ( self . band ) except : return @property def cycle_date ( self ): try : return datetime . strptime ( self . cycle_date , self . sdf ) . replace ( tzinfo = timezone . utc ) except Exception as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) @property def description ( self ): return self . desc @property def forecast_hour ( self ): m = self . fcst_pattern . match ( self . fcst_hr ) if m : return eval ( m [ 0 ]) else : return - 9999","title":"High Resolution Rapid Refresh"},{"location":"geoprocess/hrrr/#cumulus_geoproc.geoprocess.hrrr--high-resolution-rapid-refresh-hrrr-utilities","text":"","title":"High Resolution Rapid Refresh (HRRR) utilities"},{"location":"geoprocess/hrrr/#cumulus_geoproc.geoprocess.hrrr.HrrrIdx","text":"HRRR index (idx) files describe all elements in the grib2 file This class provides methods to parse lines from idx files and return a band number. Logic to determine if the resulting parse values are done outside this class. Source code in cumulus_geoproc/geoprocess/hrrr/__init__.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 class HrrrIdx : \"\"\"HRRR index (idx) files describe all elements in the grib2 file This class provides methods to parse lines from idx files and return a band number. Logic to determine if the resulting parse values are done outside this class. \"\"\" def __init__ ( self ): self . el = None self . sep_ = \":\" self . band = None self . cycle_dt = None self . desc = None self . fcst_hr = None self . sdf = \"%Y%m %d %H%M\" self . fcst_pattern = re . compile ( r \"\\d+-?\\d+\" ) def __repr__ ( self ): return f \" { __class__ . __name__ } ()\" @property def element ( self ): return self . el def sep ( self , s : str ): self . sep = s def linex ( self , line : str ): try : parts = line . split ( \":\" ) self . band = parts [ 0 ] self . cycle_dt = parts [ 2 ][ 2 :] self . el = parts [ 3 ] self . desc = parts [ 4 ] self . fcst_hr = parts [ 5 ] except ( ValueError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) @property def raster_band ( self ): try : return int ( self . band ) except : return @property def cycle_date ( self ): try : return datetime . strptime ( self . cycle_date , self . sdf ) . replace ( tzinfo = timezone . utc ) except Exception as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) @property def description ( self ): return self . desc @property def forecast_hour ( self ): m = self . fcst_pattern . match ( self . fcst_hr ) if m : return eval ( m [ 0 ]) else : return - 9999","title":"HrrrIdx"},{"location":"geoprocess/snodas/","text":"Geoprocessing SNODAS state variables Reference: https://nsidc.org/sites/nsidc.org/files/G02158-V001-UserGuide_2.pdf cold_content ( translated_tif ) Compute cold content as a function of SWE and snow pack avg temp Parameters: Name Type Description Default translated_tif dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } required Returns: Type Description dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Source code in cumulus_geoproc/geoprocess/snodas/__init__.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def cold_content ( translated_tif ): \"\"\"Compute cold content as a function of SWE and snow pack avg temp Parameters ---------- translated_tif : dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Returns ------- dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } \"\"\" coldcontent_code = \"2072\" swe_code = \"1034\" avg_temp_sp = \"1038\" try : swe = translated_tif [ swe_code ][ \"file\" ] swe_dt = translated_tif [ swe_code ][ \"datetime\" ] avg_temp = translated_tif [ avg_temp_sp ][ \"file\" ] except KeyError as ex : logger . warning ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return cold_content_filename = swe . replace ( swe_code , coldcontent_code ) temp_cold_content = swe . replace ( swe_code , \"9999\" ) try : cgdal . gdal_calculate ( \"-A\" , swe , \"-B\" , avg_temp , \"--outfile\" , temp_cold_content , \"--calc\" , \"A.astype(numpy.float32) * 2114 * (B.astype(numpy.float32) - 273) / 333000\" , \"--quiet\" , ) gdal . Translate ( tif := cold_content_filename , temp_cold_content , format = \"COG\" , creationOptions = [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) except RuntimeError as ex : logger . debug ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return None return { coldcontent_code : { \"file\" : tif , \"filetype\" : product_code [ coldcontent_code ][ \"product\" ], \"datetime\" : swe_dt , \"version\" : None , } } no_data_value ( dt ) No data value determined by time Parameters: Name Type Description Default dt datetime datetime object required Returns: Type Description int raster no data value Source code in cumulus_geoproc/geoprocess/snodas/__init__.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def no_data_value ( dt : datetime ): \"\"\"No data value determined by time Parameters ---------- dt : datetime datetime object Returns ------- int raster no data value \"\"\" dt_nodata = datetime ( 2011 , 1 , 24 , 0 , 0 , tzinfo = timezone . utc ) if dt < dt_nodata : return \"55537\" else : return \"-9999\" snow_melt_mm ( translated_tif ) Dictionary of tiffs generated from gdal translate Parameters: Name Type Description Default translated_tif dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } required Returns: Type Description dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Source code in cumulus_geoproc/geoprocess/snodas/__init__.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def snow_melt_mm ( translated_tif : dict ): \"\"\"Dictionary of tiffs generated from gdal translate Parameters ---------- translated_tif : dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Returns ------- dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } \"\"\" snowmelt_code = \"1044\" snowmelt_code_mm = \"3333\" try : snowmelt = translated_tif [ snowmelt_code ][ \"file\" ] snowmelt_dt = translated_tif [ snowmelt_code ][ \"datetime\" ] except KeyError as ex : logger . warning ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return snowmelt_mm = snowmelt . replace ( snowmelt_code , snowmelt_code_mm ) temp_snowmelt_mm = snowmelt . replace ( snowmelt_code , \"9999\" ) # convert snow melt runoff as meters / 100_000 to mm # 100_000 is the scale factor getting values to meters try : cgdal . gdal_calculate ( \"-A\" , snowmelt , \"--outfile\" , temp_snowmelt_mm , \"--calc\" , \"A.astype(numpy.float32) / 100_000 * 1000\" , \"--quiet\" , \"--overwrite\" , ) gdal . Translate ( tif := snowmelt_mm , temp_snowmelt_mm , format = \"COG\" , creationOptions = [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) except RuntimeError as ex : logger . debug ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return None return { snowmelt_code_mm : { \"file\" : tif , \"filetype\" : product_code [ snowmelt_code_mm ][ \"product\" ], \"datetime\" : snowmelt_dt , \"version\" : None , } } SNODAS interpolation is_lakefix ( dt , code ) Determine if needing 'lakefix' Parameters: Name Type Description Default dt datetime datetime object required code str parameter code related to SNODAS parameters required Returns: Type Description bool True | False if needing 'lakefix' Source code in cumulus_geoproc/geoprocess/snodas/interpolate.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def is_lakefix ( dt : datetime , code : str ): \"\"\"Determine if needing 'lakefix' Parameters ---------- dt : datetime datetime object code : str parameter code related to SNODAS parameters Returns ------- bool True | False if needing 'lakefix' \"\"\" codes = ( \"1034\" , \"1036\" ) dt_after = datetime ( 2014 , 10 , 9 , 0 , 0 , tzinfo = timezone . utc ) dt_before = datetime ( 2019 , 10 , 10 , 0 , 0 , tzinfo = timezone . utc ) if ( dt_after <= dt <= dt_before ) and code in codes : return True else : return False snodas ( cfg , dst ) async Main method building asyncio tasks Parameters: Name Type Description Default cfg namedtuple namedtuple with SQS message as attributes required dst str FQPN to temporary directory required Returns: Type Description List [ dict [ str , str ]] List of dictionary objects with attributes needed to upload to S3 Source code in cumulus_geoproc/geoprocess/snodas/interpolate.py 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 async def snodas ( cfg : namedtuple , dst : str ): \"\"\"Main method building asyncio tasks Parameters ---------- cfg : namedtuple namedtuple with SQS message as attributes dst : str FQPN to temporary directory Returns ------- List[dict[str, str]] List of dictionary objects with attributes needed to upload to S3 \"\"\" # products that don't actually get interpolated but don't know why no_interp = ( \"2072\" , \"3333\" , \"1038\" , ) tasks = [] dt = ( datetime . strptime ( cfg . datetime , \"%Y%m %d \" ) . replace ( hour = 6 ) . replace ( tzinfo = timezone . utc ) ) nodata_value = no_data_value ( dt ) # determine spatial coverage; date dependent _sc = ( \"us\" if ( datetime ( 2003 , 1 , 1 , tzinfo = timezone . utc ) <= dt < datetime ( 2010 , 2 , 17 , tzinfo = timezone . utc ) ) else \"zz\" ) logger . debug ( f \"Spatial coverage is { _sc } \" ) for code in ( \"1034\" , \"1036\" , \"1038\" , \"3333\" , \"2072\" ): filename = Template . substitute ( product_code [ code ][ \"file_template\" ], SC = _sc , YMD = cfg . datetime ) product = product_code [ code ][ \"product\" ] + \"-interpolated\" key = ( CUMULUS_PRODUCTS_BASEKEY + \"/\" + product_code [ code ][ \"product\" ] + \"/\" + filename ) lakefix = is_lakefix ( dt , code , ) max_dist = 0 if code in no_interp else cfg . max_distance if download_file := boto . s3_download_file ( cfg . bucket , key , dst = dst ): tasks . append ( asyncio . create_task ( snodas_interp_task ( download_file , product , dt , max_dist , nodata_value , lakefix , ) ) ) # return the list of objects that are not None return_objs = [] for task in tasks : result = await task if result is not None : return_objs . append ( result ) return return_objs snodas_interp_task ( filepath , product , dt , max_dist , nodata , lakefix = False ) async SNODAS interpolation task method used with asyncio Parameters: Name Type Description Default filepath str FQPN to processed SNODAS COG required product str Cumulus product name required dt datetime datetime object required max_dist str maximum distance in pixel for gdal_fillnodata required nodata str raster no data value required lakefix bool , optional determine if product needs 'lakefix', by default False False Returns: Type Description dict [ str , str ] | None Dictionary of attributes needed to upload to S3 or None Source code in cumulus_geoproc/geoprocess/snodas/interpolate.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 async def snodas_interp_task ( filepath : str , product : str , dt : datetime , max_dist : str , nodata : str , lakefix : bool = False , ): \"\"\"SNODAS interpolation task method used with asyncio Parameters ---------- filepath : str FQPN to processed SNODAS COG product : str Cumulus product name dt : datetime datetime object max_dist : str maximum distance in pixel for gdal_fillnodata nodata : str raster no data value lakefix : bool, optional determine if product needs 'lakefix', by default False Returns ------- dict[str, str] | None Dictionary of attributes needed to upload to S3 or None \"\"\" try : dst , filename = os . path . split ( filepath ) if lakefix : # get the no data masking raster masking_raster = pkg_resources . resource_filename ( __package__ , \"data/no_data_areas_swe_20140201.tif\" ) lakefix_tif = os . path . join ( dst , file_extension ( filename , suffix = \".tiff\" ), ) # set zeros as no data (-9999) cgdal . gdal_calculate ( \"-A\" , filepath , \"-B\" , masking_raster , \"--outfile\" , lakefix_tif , \"--calc\" , f \"numpy.where((A == 0) & (B == { nodata } ), { nodata } , A)\" , \"--NoDataValue\" , nodata , \"--quiet\" , ) filepath = lakefix_tif # -of GTiff required here because COG has no Create(); therefore GTiff # driver used with creationOptions to be COG fill_tif = os . path . join ( dst , file_extension ( filename , suffix = \"-interpolated.tiff\" ) ) # fillnodata to GTiff if max_dist == 0 or ( cgdal . gdal_fillnodataval ( filepath , fill_tif , \"-q\" , \"-md\" , str ( max_dist ), ) != 0 ): logger . info ( \"gdal_fillnodata.py not executed\" ) fill_tif = filepath # convert to COG gdal . Translate ( tif := os . path . join ( dst , file_extension ( filename , suffix = \"-interpolated.tif\" ) ), fill_tif , format = \"COG\" , creationOptions = [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) return { \"file\" : tif , \"filetype\" : product , \"datetime\" : dt . isoformat (), \"version\" : None , } except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None Metadata parser to_dictionary ( src ) ASCII input from SNODAS metadata to a dictionary all keys are psuedo-slugified Parameters: Name Type Description Default src str SNODAS metadata as .txt required Returns: Type Description dict | None dictionary of metadata parameters and their values or None Source code in cumulus_geoproc/geoprocess/snodas/metaparse.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def to_dictionary ( src : str ): \"\"\"ASCII input from SNODAS metadata to a dictionary all keys are psuedo-slugified Parameters ---------- src : str SNODAS metadata as .txt Returns ------- dict | None dictionary of metadata parameters and their values or None \"\"\" try : with open ( src , \"r\" ) as fh : config_dict = {} for line in fh . readlines (): k , v = line . split ( \":\" )[: 2 ] k = k . replace ( \" \" , \"_\" ) . replace ( \"-\" , \"_\" ) . lower () v = v . strip () # try make the string an int or float if a number try : v = int ( v ) if v . isdigit () else float ( v ) except : pass config_dict [ k ] = v except FileNotFoundError as ex : return return config_dict to_namedtuple ( src , name = 'Metadata' ) Use to_dictionary to generate a namedtuple Parameters: Name Type Description Default src str SNODAS metadata as .txt required name str , optional collections.namedtuple name, by default \"Metadata\" 'Metadata' Returns: Type Description collections . namedtuple namedtuple Source code in cumulus_geoproc/geoprocess/snodas/metaparse.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def to_namedtuple ( src : str , name : str = \"Metadata\" ): \"\"\"Use to_dictionary to generate a namedtuple Parameters ---------- src : str SNODAS metadata as .txt name : str, optional collections.namedtuple name, by default \"Metadata\" Returns ------- collections.namedtuple namedtuple \"\"\" mdata = to_dictionary ( src ) if isinstance ( mdata , dict ): return namedtuple ( name , mdata . keys ())( * mdata . values ()) write_hdr ( src , / , columns , rows ) Write a header file (hdr) Parameters: Name Type Description Default src str SNODAS metadata as .txt required columns int number of columns from the metadata text file required rows int number of rows from the metadata text file required Returns: Type Description str FQPN to the written hdr file | None Source code in cumulus_geoproc/geoprocess/snodas/metaparse.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def write_hdr ( src : str , / , columns : int , rows : int ): \"\"\"Write a header file (hdr) Parameters ---------- src : str SNODAS metadata as .txt columns: int number of columns from the metadata text file rows: int number of rows from the metadata text file Returns ------- str FQPN to the written hdr file | None \"\"\" try : if src . endswith ( \".txt\" ): with open ( hdr_file := src . replace ( \".txt\" , \".hdr\" ), \"w\" ) as fh : # dedent removing common indentation and lstrip to remove first \\n hdr = dedent ( f \"\"\" ENVI samples = { columns } lines = { rows } bands = 1 header offset = 0 file type = ENVI Standard data type = 2 interleave = bsq byte order = 1 \"\"\" ) fh . write ( hdr . lstrip ()) return hdr_file except OSError as ex : return","title":"Snow Data Assimilation System"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.cold_content","text":"Compute cold content as a function of SWE and snow pack avg temp Parameters: Name Type Description Default translated_tif dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } required Returns: Type Description dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Source code in cumulus_geoproc/geoprocess/snodas/__init__.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def cold_content ( translated_tif ): \"\"\"Compute cold content as a function of SWE and snow pack avg temp Parameters ---------- translated_tif : dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Returns ------- dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } \"\"\" coldcontent_code = \"2072\" swe_code = \"1034\" avg_temp_sp = \"1038\" try : swe = translated_tif [ swe_code ][ \"file\" ] swe_dt = translated_tif [ swe_code ][ \"datetime\" ] avg_temp = translated_tif [ avg_temp_sp ][ \"file\" ] except KeyError as ex : logger . warning ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return cold_content_filename = swe . replace ( swe_code , coldcontent_code ) temp_cold_content = swe . replace ( swe_code , \"9999\" ) try : cgdal . gdal_calculate ( \"-A\" , swe , \"-B\" , avg_temp , \"--outfile\" , temp_cold_content , \"--calc\" , \"A.astype(numpy.float32) * 2114 * (B.astype(numpy.float32) - 273) / 333000\" , \"--quiet\" , ) gdal . Translate ( tif := cold_content_filename , temp_cold_content , format = \"COG\" , creationOptions = [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) except RuntimeError as ex : logger . debug ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return None return { coldcontent_code : { \"file\" : tif , \"filetype\" : product_code [ coldcontent_code ][ \"product\" ], \"datetime\" : swe_dt , \"version\" : None , } }","title":"cold_content()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.no_data_value","text":"No data value determined by time Parameters: Name Type Description Default dt datetime datetime object required Returns: Type Description int raster no data value Source code in cumulus_geoproc/geoprocess/snodas/__init__.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def no_data_value ( dt : datetime ): \"\"\"No data value determined by time Parameters ---------- dt : datetime datetime object Returns ------- int raster no data value \"\"\" dt_nodata = datetime ( 2011 , 1 , 24 , 0 , 0 , tzinfo = timezone . utc ) if dt < dt_nodata : return \"55537\" else : return \"-9999\"","title":"no_data_value()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.snow_melt_mm","text":"Dictionary of tiffs generated from gdal translate Parameters: Name Type Description Default translated_tif dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } required Returns: Type Description dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Source code in cumulus_geoproc/geoprocess/snodas/__init__.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 def snow_melt_mm ( translated_tif : dict ): \"\"\"Dictionary of tiffs generated from gdal translate Parameters ---------- translated_tif : dict \"product_code\": { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } Returns ------- dict { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } \"\"\" snowmelt_code = \"1044\" snowmelt_code_mm = \"3333\" try : snowmelt = translated_tif [ snowmelt_code ][ \"file\" ] snowmelt_dt = translated_tif [ snowmelt_code ][ \"datetime\" ] except KeyError as ex : logger . warning ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return snowmelt_mm = snowmelt . replace ( snowmelt_code , snowmelt_code_mm ) temp_snowmelt_mm = snowmelt . replace ( snowmelt_code , \"9999\" ) # convert snow melt runoff as meters / 100_000 to mm # 100_000 is the scale factor getting values to meters try : cgdal . gdal_calculate ( \"-A\" , snowmelt , \"--outfile\" , temp_snowmelt_mm , \"--calc\" , \"A.astype(numpy.float32) / 100_000 * 1000\" , \"--quiet\" , \"--overwrite\" , ) gdal . Translate ( tif := snowmelt_mm , temp_snowmelt_mm , format = \"COG\" , creationOptions = [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) except RuntimeError as ex : logger . debug ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return None return { snowmelt_code_mm : { \"file\" : tif , \"filetype\" : product_code [ snowmelt_code_mm ][ \"product\" ], \"datetime\" : snowmelt_dt , \"version\" : None , } } SNODAS interpolation","title":"snow_melt_mm()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.interpolate.is_lakefix","text":"Determine if needing 'lakefix' Parameters: Name Type Description Default dt datetime datetime object required code str parameter code related to SNODAS parameters required Returns: Type Description bool True | False if needing 'lakefix' Source code in cumulus_geoproc/geoprocess/snodas/interpolate.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def is_lakefix ( dt : datetime , code : str ): \"\"\"Determine if needing 'lakefix' Parameters ---------- dt : datetime datetime object code : str parameter code related to SNODAS parameters Returns ------- bool True | False if needing 'lakefix' \"\"\" codes = ( \"1034\" , \"1036\" ) dt_after = datetime ( 2014 , 10 , 9 , 0 , 0 , tzinfo = timezone . utc ) dt_before = datetime ( 2019 , 10 , 10 , 0 , 0 , tzinfo = timezone . utc ) if ( dt_after <= dt <= dt_before ) and code in codes : return True else : return False","title":"is_lakefix()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.interpolate.snodas","text":"Main method building asyncio tasks Parameters: Name Type Description Default cfg namedtuple namedtuple with SQS message as attributes required dst str FQPN to temporary directory required Returns: Type Description List [ dict [ str , str ]] List of dictionary objects with attributes needed to upload to S3 Source code in cumulus_geoproc/geoprocess/snodas/interpolate.py 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 async def snodas ( cfg : namedtuple , dst : str ): \"\"\"Main method building asyncio tasks Parameters ---------- cfg : namedtuple namedtuple with SQS message as attributes dst : str FQPN to temporary directory Returns ------- List[dict[str, str]] List of dictionary objects with attributes needed to upload to S3 \"\"\" # products that don't actually get interpolated but don't know why no_interp = ( \"2072\" , \"3333\" , \"1038\" , ) tasks = [] dt = ( datetime . strptime ( cfg . datetime , \"%Y%m %d \" ) . replace ( hour = 6 ) . replace ( tzinfo = timezone . utc ) ) nodata_value = no_data_value ( dt ) # determine spatial coverage; date dependent _sc = ( \"us\" if ( datetime ( 2003 , 1 , 1 , tzinfo = timezone . utc ) <= dt < datetime ( 2010 , 2 , 17 , tzinfo = timezone . utc ) ) else \"zz\" ) logger . debug ( f \"Spatial coverage is { _sc } \" ) for code in ( \"1034\" , \"1036\" , \"1038\" , \"3333\" , \"2072\" ): filename = Template . substitute ( product_code [ code ][ \"file_template\" ], SC = _sc , YMD = cfg . datetime ) product = product_code [ code ][ \"product\" ] + \"-interpolated\" key = ( CUMULUS_PRODUCTS_BASEKEY + \"/\" + product_code [ code ][ \"product\" ] + \"/\" + filename ) lakefix = is_lakefix ( dt , code , ) max_dist = 0 if code in no_interp else cfg . max_distance if download_file := boto . s3_download_file ( cfg . bucket , key , dst = dst ): tasks . append ( asyncio . create_task ( snodas_interp_task ( download_file , product , dt , max_dist , nodata_value , lakefix , ) ) ) # return the list of objects that are not None return_objs = [] for task in tasks : result = await task if result is not None : return_objs . append ( result ) return return_objs","title":"snodas()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.interpolate.snodas_interp_task","text":"SNODAS interpolation task method used with asyncio Parameters: Name Type Description Default filepath str FQPN to processed SNODAS COG required product str Cumulus product name required dt datetime datetime object required max_dist str maximum distance in pixel for gdal_fillnodata required nodata str raster no data value required lakefix bool , optional determine if product needs 'lakefix', by default False False Returns: Type Description dict [ str , str ] | None Dictionary of attributes needed to upload to S3 or None Source code in cumulus_geoproc/geoprocess/snodas/interpolate.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 async def snodas_interp_task ( filepath : str , product : str , dt : datetime , max_dist : str , nodata : str , lakefix : bool = False , ): \"\"\"SNODAS interpolation task method used with asyncio Parameters ---------- filepath : str FQPN to processed SNODAS COG product : str Cumulus product name dt : datetime datetime object max_dist : str maximum distance in pixel for gdal_fillnodata nodata : str raster no data value lakefix : bool, optional determine if product needs 'lakefix', by default False Returns ------- dict[str, str] | None Dictionary of attributes needed to upload to S3 or None \"\"\" try : dst , filename = os . path . split ( filepath ) if lakefix : # get the no data masking raster masking_raster = pkg_resources . resource_filename ( __package__ , \"data/no_data_areas_swe_20140201.tif\" ) lakefix_tif = os . path . join ( dst , file_extension ( filename , suffix = \".tiff\" ), ) # set zeros as no data (-9999) cgdal . gdal_calculate ( \"-A\" , filepath , \"-B\" , masking_raster , \"--outfile\" , lakefix_tif , \"--calc\" , f \"numpy.where((A == 0) & (B == { nodata } ), { nodata } , A)\" , \"--NoDataValue\" , nodata , \"--quiet\" , ) filepath = lakefix_tif # -of GTiff required here because COG has no Create(); therefore GTiff # driver used with creationOptions to be COG fill_tif = os . path . join ( dst , file_extension ( filename , suffix = \"-interpolated.tiff\" ) ) # fillnodata to GTiff if max_dist == 0 or ( cgdal . gdal_fillnodataval ( filepath , fill_tif , \"-q\" , \"-md\" , str ( max_dist ), ) != 0 ): logger . info ( \"gdal_fillnodata.py not executed\" ) fill_tif = filepath # convert to COG gdal . Translate ( tif := os . path . join ( dst , file_extension ( filename , suffix = \"-interpolated.tif\" ) ), fill_tif , format = \"COG\" , creationOptions = [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) return { \"file\" : tif , \"filetype\" : product , \"datetime\" : dt . isoformat (), \"version\" : None , } except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None Metadata parser","title":"snodas_interp_task()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.metaparse.to_dictionary","text":"ASCII input from SNODAS metadata to a dictionary all keys are psuedo-slugified Parameters: Name Type Description Default src str SNODAS metadata as .txt required Returns: Type Description dict | None dictionary of metadata parameters and their values or None Source code in cumulus_geoproc/geoprocess/snodas/metaparse.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def to_dictionary ( src : str ): \"\"\"ASCII input from SNODAS metadata to a dictionary all keys are psuedo-slugified Parameters ---------- src : str SNODAS metadata as .txt Returns ------- dict | None dictionary of metadata parameters and their values or None \"\"\" try : with open ( src , \"r\" ) as fh : config_dict = {} for line in fh . readlines (): k , v = line . split ( \":\" )[: 2 ] k = k . replace ( \" \" , \"_\" ) . replace ( \"-\" , \"_\" ) . lower () v = v . strip () # try make the string an int or float if a number try : v = int ( v ) if v . isdigit () else float ( v ) except : pass config_dict [ k ] = v except FileNotFoundError as ex : return return config_dict","title":"to_dictionary()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.metaparse.to_namedtuple","text":"Use to_dictionary to generate a namedtuple Parameters: Name Type Description Default src str SNODAS metadata as .txt required name str , optional collections.namedtuple name, by default \"Metadata\" 'Metadata' Returns: Type Description collections . namedtuple namedtuple Source code in cumulus_geoproc/geoprocess/snodas/metaparse.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def to_namedtuple ( src : str , name : str = \"Metadata\" ): \"\"\"Use to_dictionary to generate a namedtuple Parameters ---------- src : str SNODAS metadata as .txt name : str, optional collections.namedtuple name, by default \"Metadata\" Returns ------- collections.namedtuple namedtuple \"\"\" mdata = to_dictionary ( src ) if isinstance ( mdata , dict ): return namedtuple ( name , mdata . keys ())( * mdata . values ())","title":"to_namedtuple()"},{"location":"geoprocess/snodas/#cumulus_geoproc.geoprocess.snodas.metaparse.write_hdr","text":"Write a header file (hdr) Parameters: Name Type Description Default src str SNODAS metadata as .txt required columns int number of columns from the metadata text file required rows int number of rows from the metadata text file required Returns: Type Description str FQPN to the written hdr file | None Source code in cumulus_geoproc/geoprocess/snodas/metaparse.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def write_hdr ( src : str , / , columns : int , rows : int ): \"\"\"Write a header file (hdr) Parameters ---------- src : str SNODAS metadata as .txt columns: int number of columns from the metadata text file rows: int number of rows from the metadata text file Returns ------- str FQPN to the written hdr file | None \"\"\" try : if src . endswith ( \".txt\" ): with open ( hdr_file := src . replace ( \".txt\" , \".hdr\" ), \"w\" ) as fh : # dedent removing common indentation and lstrip to remove first \\n hdr = dedent ( f \"\"\" ENVI samples = { columns } lines = { rows } bands = 1 header offset = 0 file type = ENVI Standard data type = 2 interleave = bsq byte order = 1 \"\"\" ) fh . write ( hdr . lstrip ()) return hdr_file except OSError as ex : return","title":"write_hdr()"},{"location":"processors/processors/","text":"Initialize Geo Processor Plugins; source undefined Colorado Basin River Forecast Center (CBRFC) Multisensor Precipitation Estimates (MPE) process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/cbrfc-mpe.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list North Central River Forecast Center Multisensor Precipitation Estimates (MPE) process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncrfc-mpe-01h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list Lower Mississippi River Forecast Center (LMRFC) Quantitative Precipitation Estimates (QPF) 6 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/lmrfc-qpf-06h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list MRMS MultiSensor QPE 01H Pass1 process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-multisensor-qpe-01h-pass1.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass1\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list National Blend of Models (NBM) CONUS 1hour Forecasted Airtemp and QPF process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nbm-co-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] filetype_elements = { \"nbm-co-airtemp\" : { \"GRIB_ELEMENT\" : \"T\" , \"GRIB_SHORT_NAME\" : \"2-HTGL\" , \"GRIB_UNIT\" : \"[C]\" , }, \"nbm-co-qpf\" : { \"GRIB_ELEMENT\" : \"QPF01\" , \"GRIB_SHORT_NAME\" : \"0-SFC\" , }, } try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) for filetype , attr in filetype_elements . items (): try : if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) dt_valid_str = dt_valid . strftime ( \"%Y%m %d \" ) filename_ = utils . file_extension ( filename , suffix = f \"- { dt_valid_str } - { filetype } .tif\" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : filetype , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ) logger . debug ( f \"Appended Payload: { outfile_list [ - 1 ] } \" ) except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list South East River Forecast Center Quantitative Precipitaton Forecast 6 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/serfc-qpf-06h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ()( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list NCEP RTMA RU ANL Airtemp process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-rtma-ru-anl-airtemp.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list NOHRSC SNODAS Assimilated Inside the original assim_layers_YYYYMMDDHH.tar file: Inside a folder that looks like: ssm1054_2022012212.20220122134004 (without the word 'east') There is a file that looks like: ssm1054_2022012212.nc.gz Need to uncompress that NetCDF file process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nohrsc-snodas-assimilated.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] acquirable = \"nohrsc-snodas-swe-corrections\" try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) # extract the member from the tar using this pattern member_pattern = re . compile ( r \"ssm1054_\\d+.\\d+/ssm1054_\\d+.nc.gz\" ) with tarfile . open ( src ) as tar : for member in tar . getmembers (): if member_pattern . match ( member . name ): tar . extract ( member , path = dst ) filename = os . path . join ( dst , member . name ) # decompress the extracted member snodas_assim = utils . decompress ( filename , dst ) logger . debug ( f \" { snodas_assim =} \" ) filename_ = utils . file_extension ( snodas_assim ) with Dataset ( snodas_assim , \"r\" ) as ncds : lon = ncds . variables [ \"lon\" ][:] lat = ncds . variables [ \"lat\" ][:] data = ncds . variables [ \"Data\" ] crs = ncds . variables [ \"crs\" ] data_vals = data [:] valid_time = datetime . fromisoformat ( data . stop_date ) . replace ( tzinfo = timezone . utc ) xmin , ymin , xmax , ymax = ( lon . min (), lat . min (), lon . max (), lat . max (), ) nrows , ncols = data . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , snodas_assim + \".tmp.tif\" ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () # srs.ImportFromEPSG(4326) srs . SetWellKnownGeogCS ( crs . horizontal_datum ) raster . SetProjection ( srs . ExportToWkt ()) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs data_vals = numpy . flipud ( data_vals ) band . WriteArray ( data_vals ) raster . FlushCache () raster = None cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_ ), tmptif , noData = data . no_data_value , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) # Append dictionary object to outfile list outfile_list . append ( { \"filetype\" : \"nohrsc-snodas-swe-corrections\" , \"file\" : tif , \"datetime\" : valid_time . isoformat (), \"version\" : None , } ) logger . debug ( f \"Outfile Append: { outfile_list [ - 1 ] } \" ) break except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list PRISM Climate Group Daily (D2) total precipitation (ppt)(rain+melted snow) Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-ppt-stable.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list NOHRSC SNODAS Unmasked process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nohrsc-snodas-unmasked.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] paramater_codes = [ \"1034\" , \"1036\" , \"1038\" , \"1044\" ] try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) # decompress the tar and gzip files in the tar decompressed_files = utils . decompress ( src , dst , recursive = True ) if not os . path . isdir ( decompressed_files ): raise Exception ( f \"Not a directory: { decompressed_files } \" ) # generator for only the files ending with .txt txt_files = ( f for f in os . listdir ( decompressed_files ) if f . endswith ( \".txt\" )) translate_to_tif = {} # create tif files for only the files needed for txt_file in txt_files : snodas_product_code = txt_file [ 8 : 12 ] if snodas_product_code in paramater_codes : fqpn = os . path . join ( decompressed_files , txt_file ) meta_ntuple = metaparse . to_namedtuple ( fqpn ) data_filename = meta_ntuple . data_file_pathname region = txt_file [: 2 ] stop_date = datetime ( meta_ntuple . stop_year , meta_ntuple . stop_month , meta_ntuple . stop_day , # Metadata value `Stop hour: 5` present in earlier SNODAS files results in incorrect timestamp if used directly as the timestamp for the data # This has since been corrected in the SNODAS metadata .txt files. `Stop hour: 5` is no longer present in current files as of today (2022-08-08) # Additional Information: https://github.com/USACE/cumulus/issues/264, https://github.com/USACE/cumulus/issues/244#issuecomment-1209465407 meta_ntuple . stop_hour if meta_ntuple . stop_year >= 2022 else 6 , meta_ntuple . stop_minute , meta_ntuple . stop_second , tzinfo = timezone . utc , ) # FQPN to data file datafile_pathname = os . path . join ( decompressed_files , data_filename ) logger . debug ( f \"Data File Path: { datafile_pathname } \" ) # write hdr so gdal can tranlate hdr_file = metaparse . write_hdr ( fqpn , meta_ntuple . number_of_columns , meta_ntuple . number_of_rows ) # translate to tif if hdr_file is not None : # set translate options ds = gdal . Open ( datafile_pathname ) cgdal . gdal_translate_options ( tif := file_extension ( datafile_pathname , suffix = \".tif\" ), ds , outputSRS = f \"+proj=longlat +ellps= { meta_ntuple . horizontal_datum } +datum= { meta_ntuple . horizontal_datum } +no_defs\" , noData = int ( meta_ntuple . no_data_value ), outputBounds = [ meta_ntuple . minimum_x_axis_coordinate , meta_ntuple . maximum_y_axis_coordinate , meta_ntuple . maximum_x_axis_coordinate , meta_ntuple . minimum_y_axis_coordinate , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) ds = None # add tif dictionary to compute cold content translate_to_tif [ snodas_product_code ] = { \"file\" : tif , \"filetype\" : snodas . product_code [ snodas_product_code ][ \"product\" ], \"datetime\" : stop_date . isoformat (), \"version\" : None , } logger . debug ( f \"Update Tif: { translate_to_tif [ snodas_product_code ] } \" ) # cold content = swe * 2114 * snowtemp (degc) / 333000 # id 2072 if result := snodas . cold_content ( translate_to_tif ): translate_to_tif . update ( result ) logger . debug ( f \"Cold content product computed and dictionary updated\" ) # convert snow melt to mm if result := snodas . snow_melt_mm ( translate_to_tif ): translate_to_tif . update ( result ) # remove snowmelt with unit meters and scale factor 100_000 _ = translate_to_tif . pop ( \"1044\" , None ) logger . debug ( f \"Snow melt product conversion and original popped from dictionary\" ) outfile_list . extend ( list ( translate_to_tif . values ())) except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list PRISM Climate Group Daily (D2) total precipitation (ppt)(rain+melted snow) Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-ppt-early.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list NDGD LEIA98 Precipitation process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndgd-ltia98-airtemp.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = {} filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list NAEFS Mean 6 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/naefs-mean-06h.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) products = { \"QPF\" : \"naefs-mean-qpf-06h\" , \"QTF\" : \"naefs-mean-qtf-06h\" } with Dataset ( src , \"r\" ) as ncds : time_str = re . match ( r \"\\d {4} -\\d {2} -\\d {2} \\d+:\\d+:\\d+\" , ncds . date_created ) date_created = datetime . fromisoformat ( time_str [ 0 ]) . replace ( tzinfo = timezone . utc ) lat = ncds . variables [ \"y\" ][:] lon = ncds . variables [ \"x\" ][:] xmin , ymin , xmax , ymax = lon . min (), lat . min (), lon . max (), lat . max () wkt = ncds . variables [ \"crs\" ] . crs_wkt logger . debug ( f \"WKT: { wkt } \" ) nctime = ncds . variables [ \"time\" ] for k , acquirable_ in products . items (): logger . debug ( f \"Product Variable: { k } \" ) logger . debug ( f \"Product Acquirable: { acquirable_ } \" ) ncvar = ncds . variables [ k ] nodata = ncvar . _FillValue _ , nrows , ncols = ncvar . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) _data = None for dt in num2date ( nctime [:], nctime . units , only_use_cftime_datetimes = False ): dt_valid = dt . replace ( tzinfo = timezone . utc ) idx = date2index ( dt , nctime ) nctime_str = datetime . strftime ( dt , \"%Y%m %d %H%M\" ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , filename . replace ( \".nc\" , f \"- { k } - { nctime_str } -tmp.tif\" ) ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () srs . ImportFromWkt ( wkt ) raster . SetProjection ( wkt ) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs _data = ncvar [ idx ] _data = numpy . flipud ( _data ) band . WriteArray ( _data ) raster . FlushCache () raster = None cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , tmptif . replace ( \"-tmp.tif\" , \".tif\" )), tmptif , noData = nodata , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : acquirable_ , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : date_created . isoformat (), } ) except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : raster = None return outfile_list Middle Atlantic River Forecast Center National Blend of Models Surface Temperature 3 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-nbmt-03h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list MRMS MultiSensor QPE 01H Pass2 Carib process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p2-carib.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass2\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list Middle Atlantic River Forecast Center Real Time Mesoscale Analysis Surface Temperature as Observed process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-rtmat-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # closing the data source ds = None raster = None outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list North Central River Forecast Center Multisensor Precipitation Estimates (MPE) process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncrfc-rtmat-01h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list Middle Atlantic River Forecast Center National Blend of Models Surface Temperature 1 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-nbmt-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list North Central River Forecast Center Forecast Mesoscale Analysis Surface Temperature 01Hr process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncrfc-fmat-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : if dst is None : dst = os . path . dirname ( src ) for grib in gdal . ReadDir ( f \"/vsitar/ { src } \" ): try : filename = utils . file_extension ( grib , suffix = \".tif\" ) ds = gdal . Open ( f \"/vsitar/ { src } / { grib } \" ) raster = ds . GetRasterBand ( 1 ) # Compile regex to get times from timestamp time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) valid_time = ( datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) . isoformat () if valid_time_match else None ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) ref_time = ( datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) . isoformat () if ref_time_match else None ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename ), ds , ) # Append dictionary object to outfile list outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : valid_time , \"version\" : ref_time , } ) except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list NSIDC SWE v1 process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nsidc-ua-swe-sd-v1.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] # Variables and their product slug nc_variables = { \"SWE\" : \"nsidc-ua-swe-v1\" , \"DEPTH\" : \"nsidc-ua-snowdepth-v1\" , } try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) for nc_variable , nc_slug in nc_variables . items (): ds = gdal . Open ( f \"NETCDF: { src } : { nc_variable } \" ) # set the start time time_pattern = re . compile ( r \"\\w+ \\w+ (\\d {4} -\\d {2} -\\d {2} )\" ) day_since_str = time_pattern . match ( ds . GetMetadataItem ( \"time#units\" )) day_since = datetime . fromisoformat ( day_since_str [ 1 ]) . replace ( tzinfo = timezone . utc ) for band_number in range ( 1 , ds . RasterCount + 1 ): # set the bands date raster = ds . GetRasterBand ( band_number ) delta_days = raster . GetMetadataItem ( \"NETCDF_DIM_time\" ) band_date = day_since + timedelta ( days = int ( delta_days )) datetime_str = band_date . strftime ( \"%Y%m %d \" ) filename_ = utils . file_extension ( filename , suffix = f \"_ { datetime_str } _ { nc_variable } .tif\" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_ ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : nc_slug , \"file\" : tif , \"datetime\" : band_date . isoformat (), \"version\" : None , } ) except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list WPC QPF 2.5km process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/wpc-qpf-2p5km.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP06\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list PRISM Climate Group Daily minimum temperature [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmin-stable.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) # closing the data source ds = None outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list NDGD LEIA98 Precipitation process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndgd-leia98-precip.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = {} filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list WRF Columbia Airtemp process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/wrf-columbia-airtemp.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] ncds = None try : # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ncds = Dataset ( src , \"r\" ) lon = ncds . variables [ \"lon\" ][:] lat = ncds . variables [ \"lat\" ][:] var = ncds . variables [ \"var\" ][:] time_ = ncds . variables [ \"time\" ] time_pattern = re . compile ( r \"\\w+ \\w+ (\\d {4} -\\d {2} -\\d {2} \\d+:\\d+:\\d+)\" ) time_str = time_pattern . match ( time_ . units ) since_time = datetime . fromisoformat ( time_str [ 1 ]) . replace ( tzinfo = timezone . utc ) nctimes = ( since_time + timedelta ( hours = int ( td )) for td in time_ ) xmin , ymin , xmax , ymax = lon . min (), lat . min (), lon . max (), lat . max () for i , nctime in enumerate ( nctimes ): bandx = var [ i ] nctime_str = datetime . strftime ( nctime , \"%Y_%m_ %d _T%H_%M\" ) nrows , ncols = bandx . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tmp.tif\" ) ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () srs . ImportFromEPSG ( 4326 ) raster . SetProjection ( srs . ExportToWkt ()) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs bandx = numpy . flipud ( bandx ) band . WriteArray ( bandx ) raster . FlushCache () raster = None cgdal . gdal_translate_w_overviews ( tif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tif\" )), tmptif , translate_options = { \"format\" : \"COG\" , \"bandList\" : [ 1 ], \"outputBounds\" : [ - 337997.806 , 812645.371 , 854002.194 , - 535354.629 ], \"outputSRS\" : \"+proj=lcc +lat_1=45 +lat_2=45 +lon_0=-120 +lat_0=45.80369 +x_0=0 +y_0=0 +a=6370000 +b=6370000 +units=m\" , \"creationOptions\" : [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], }, ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) try : os . remove ( tmptif ) except OSError as ex : print ( ex ) outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : nctime . isoformat (), \"version\" : datetime . utcnow (), } ) except Exception as ex : print ( ex ) finally : if ncds : ncds . close () raster = None return outfile_list MRMS MultiSensor QPE 01H Pass2 Alaska process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p2-alaska.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass2\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list Missouri Basin River Forecast Center process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/mbrfc-krf-qpe-01h.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list PRISM Climate Group Daily (D2) maximum temperature (tmax) [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmax-early.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list NDFD CONUS Airtemp process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndfd-conus-airtemp.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] # Create a dictionary of time deltas and equivalent filetype f_type_dict = { 3600 : \"ndfd-conus-airtemp-01h\" , 10800 : \"ndfd-conus-airtemp-03h\" , 21600 : \"ndfd-conus-airtemp-06h\" , } try : filename = os . path . basename ( src ) filename_ = utils . file_extension ( filename , suffix = \"\" ) filename_temp = Template ( \"$ {filename} -$ {ymd} .tif\" ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) count = ds . RasterCount time_pattern = re . compile ( r \"\\d+\" ) tdelta2 = timedelta () for band_number in range ( 1 , count + 1 ): try : tdelta1 = tdelta2 raster = ds . GetRasterBand ( band_number ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) vtime = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) rtime = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) forcast_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_FORECAST_SECONDS\" ) ) forcast_time = float ( forcast_time_match [ 0 ]) # Check the time deltas to see if they are consistant tdelta2 = timedelta ( seconds = forcast_time ) tdelta = ( tdelta2 - tdelta1 ) . seconds # Extract Band; Convert to COG if tdelta in f_type_dict : _filename = filename_temp . substitute ( filename = filename_ , ymd = vtime . strftime ( \"%Y%m %d %H%M\" ) ) logger . debug ( f \"New Filename: { _filename } \" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , _filename ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : f_type_dict [ tdelta ], \"file\" : tif , \"datetime\" : vtime . isoformat (), \"version\" : rtime . isoformat (), } ) except ( RuntimeError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : continue except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list PRISM Climate Group Daily (D2) maximum temperature (tmax) [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmax-stable.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list Lower Mississippi River Forecast Center (LMRFC) Quantitative Precipitation Estimates (QPE) 1 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/lmrfc-qpe-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list MRMS Gauge Corrected process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-gaugecorr-qpe-01h.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"GaugeCorrected_QPE_01H\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list South East River Forecast Center Quantitative Precipitation Estimates (QPE) 1 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/serfc-qpe-01h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ()( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list NDFD CONUS QPF 6 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndfd-conus-qpf-06h.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) filename_ = utils . file_extension ( filename , suffix = \"\" ) filename_temp = Template ( \"$ {filename} -$ {ymd} .tif\" ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) count = ds . RasterCount time_pattern = re . compile ( r \"\\d+\" ) for band_number in range ( 1 , count + 1 ): try : raster = ds . GetRasterBand ( band_number ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) vtime = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) rtime = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) _filename = filename_temp . substitute ( filename = filename_ , ymd = vtime . strftime ( \"%Y%m %d %H%M\" ) ) logger . debug ( f \"New Filename: { _filename } \" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , _filename ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : vtime . isoformat (), \"version\" : rtime . isoformat (), } ) except ( RuntimeError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : continue except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list Middle Atlantic River Forecast Center (MARFC) Forecast Mesoscale Analysis Temperature, Air 6 hour process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-fmat-06h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list MRMS MultiSensor QPE 01H Pass1 Alaska process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p1-alaska.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass1\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list High Resolution Rapid Refresh (HRRR) Total Precipitation HRRR file source: https://nomads.ncep.noaa.gov/pub/data/nccf/com/hrrr/prod/ 2022-04-29 Update: HRRR index files (hrrr_filename.grib2.idx) are used to determine the ever changing '01 hr Total Precipitation' raster band number. Archived HRRR products do not have idx files saved in S3, so this processor tries to account for that. process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/hrrr-total-precip.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" , \"GRIB_COMMENT\" : \"precipitation\" , \"GRIB_UNIT\" : \"[kg/(m^2)]\" , } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) # open the hrrr.grib2 file ds = gdal . Open ( src ) # Can't use index file with product downloaded by handler # Successful download means we have the idx we need # idx_file = key + \".idx\" # if hrrridx := boto.s3_download_file(bucket=bucket, key=idx_file, dst=dst): # idx = hrrr.HrrrIdx() # with open(hrrridx, \"r\") as fh: # for line in fh.readlines(): # idx.linex(line) # # This if statement means Total Precip for 01 hr forecast # if idx.element == \"APCP\" and ( # idx.forecast_hour == 0 or idx.forecast_hour == -1 # ): # band_number = idx.raster_band # if band_number is None: # raise Exception(\"Band number not found in idx: {hrrridx}\") # logger.debug(f\"Band number '{band_number}' found in {hrrridx}\") # else: # if (band_number := cgdal.find_band(ds, attr)) is None: # raise Exception(f\"Band number not found for attributes: {attr}\") # print(f\"Band number '{band_number}' found for attributes {attr}\") if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( f \"Band number not found for attributes: { attr } \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list WRF Columbia Precipitation process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/wrf-columbia-precip.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] ncds = None try : # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ncds = Dataset ( src , \"r\" ) lon = ncds . variables [ \"lon\" ][:] lat = ncds . variables [ \"lat\" ][:] var = ncds . variables [ \"var\" ][:] time_ = ncds . variables [ \"time\" ] time_pattern = re . compile ( r \"\\w+ \\w+ (\\d {4} -\\d {2} -\\d {2} \\d+:\\d+:\\d+)\" ) time_str = time_pattern . match ( time_ . units ) since_time = datetime . fromisoformat ( time_str [ 1 ]) . replace ( tzinfo = timezone . utc ) nctimes = ( since_time + timedelta ( hours = int ( td )) for td in time_ ) xmin , ymin , xmax , ymax = lon . min (), lat . min (), lon . max (), lat . max () for i , nctime in enumerate ( nctimes ): bandx = var [ i ] nctime_str = datetime . strftime ( nctime , \"%Y_%m_ %d _T%H_%M\" ) nrows , ncols = bandx . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tmp.tif\" ) ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () srs . ImportFromEPSG ( 4326 ) raster . SetProjection ( srs . ExportToWkt ()) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs bandx = numpy . flipud ( bandx ) band . WriteArray ( bandx ) raster . FlushCache () raster = None cgdal . gdal_translate_w_overviews ( tif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tif\" )), tmptif , translate_options = { \"format\" : \"COG\" , \"bandList\" : [ 1 ], \"outputBounds\" : [ - 337997.806 , 812645.371 , 854002.194 , - 535354.629 ], \"outputSRS\" : \"+proj=lcc +lat_1=45 +lat_2=45 +lon_0=-120 +lat_0=45.80369 +x_0=0 +y_0=0 +a=6370000 +b=6370000 +units=m\" , \"creationOptions\" : [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , \"NUM_THREADS=ALL_CPUS\" , ], }, ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) try : os . remove ( tmptif ) except OSError as ex : print ( ex ) outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : nctime . isoformat (), \"version\" : datetime . utcnow (), } ) except Exception as ex : print ( ex ) finally : if ncds : ncds . close () raster = None return outfile_list PRISM Climate Group Daily minimum temperature [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmin-early.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) # closing the data source ds = None outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list Missouri Basin River Forecast Center process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/mbrfc-krf-fct-airtemp-01h.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list MRMS MultiSensor QPE 01H Pass2 process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-multisensor-qpe-01h-pass2.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass2\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list MRMS MultiSensor QPE 01H Pass1 Carib process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p1-carib.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass1\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list Missouri Basin River Forecast Center process ( * , src , dst = None , acquirable = None ) Grid processor Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/mbrfc-krf-qpf-06h.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Processors"},{"location":"processors/processors/#cumulus_geoproc.processors.cbrfc-mpe--colorado-basin-river-forecast-center-cbrfc","text":"","title":"Colorado Basin River Forecast Center (CBRFC)"},{"location":"processors/processors/#cumulus_geoproc.processors.cbrfc-mpe--multisensor-precipitation-estimates-mpe","text":"","title":"Multisensor Precipitation Estimates (MPE)"},{"location":"processors/processors/#cumulus_geoproc.processors.cbrfc-mpe.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.cbrfc-mpe.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/cbrfc-mpe.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-mpe-01h--north-central-river-forecast-center","text":"Multisensor Precipitation Estimates (MPE)","title":"North Central River Forecast Center"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-mpe-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-mpe-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncrfc-mpe-01h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.lmrfc-qpf-06h--lower-mississippi-river-forecast-center-lmrfc","text":"Quantitative Precipitation Estimates (QPF) 6 hour","title":"Lower Mississippi River Forecast Center (LMRFC)"},{"location":"processors/processors/#cumulus_geoproc.processors.lmrfc-qpf-06h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.lmrfc-qpf-06h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/lmrfc-qpf-06h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-multisensor-qpe-01h-pass1--mrms-multisensor-qpe-01h-pass1","text":"","title":"MRMS MultiSensor QPE 01H Pass1"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-multisensor-qpe-01h-pass1.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-multisensor-qpe-01h-pass1.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-multisensor-qpe-01h-pass1.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass1\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list National Blend of Models (NBM) CONUS 1hour Forecasted Airtemp and QPF","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.nbm-co-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.nbm-co-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nbm-co-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] filetype_elements = { \"nbm-co-airtemp\" : { \"GRIB_ELEMENT\" : \"T\" , \"GRIB_SHORT_NAME\" : \"2-HTGL\" , \"GRIB_UNIT\" : \"[C]\" , }, \"nbm-co-qpf\" : { \"GRIB_ELEMENT\" : \"QPF01\" , \"GRIB_SHORT_NAME\" : \"0-SFC\" , }, } try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) for filetype , attr in filetype_elements . items (): try : if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) dt_valid_str = dt_valid . strftime ( \"%Y%m %d \" ) filename_ = utils . file_extension ( filename , suffix = f \"- { dt_valid_str } - { filetype } .tif\" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : filetype , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ) logger . debug ( f \"Appended Payload: { outfile_list [ - 1 ] } \" ) except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.serfc-qpf-06h--south-east-river-forecast-center","text":"Quantitative Precipitaton Forecast 6 hour","title":"South East River Forecast Center"},{"location":"processors/processors/#cumulus_geoproc.processors.serfc-qpf-06h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.serfc-qpf-06h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/serfc-qpf-06h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ()( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list NCEP RTMA RU ANL Airtemp","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-rtma-ru-anl-airtemp.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-rtma-ru-anl-airtemp.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-rtma-ru-anl-airtemp.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.nohrsc-snodas-assimilated--nohrsc-snodas-assimilated","text":"Inside the original assim_layers_YYYYMMDDHH.tar file: Inside a folder that looks like: ssm1054_2022012212.20220122134004 (without the word 'east') There is a file that looks like: ssm1054_2022012212.nc.gz Need to uncompress that NetCDF file","title":"NOHRSC SNODAS Assimilated"},{"location":"processors/processors/#cumulus_geoproc.processors.nohrsc-snodas-assimilated.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.nohrsc-snodas-assimilated.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nohrsc-snodas-assimilated.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] acquirable = \"nohrsc-snodas-swe-corrections\" try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) # extract the member from the tar using this pattern member_pattern = re . compile ( r \"ssm1054_\\d+.\\d+/ssm1054_\\d+.nc.gz\" ) with tarfile . open ( src ) as tar : for member in tar . getmembers (): if member_pattern . match ( member . name ): tar . extract ( member , path = dst ) filename = os . path . join ( dst , member . name ) # decompress the extracted member snodas_assim = utils . decompress ( filename , dst ) logger . debug ( f \" { snodas_assim =} \" ) filename_ = utils . file_extension ( snodas_assim ) with Dataset ( snodas_assim , \"r\" ) as ncds : lon = ncds . variables [ \"lon\" ][:] lat = ncds . variables [ \"lat\" ][:] data = ncds . variables [ \"Data\" ] crs = ncds . variables [ \"crs\" ] data_vals = data [:] valid_time = datetime . fromisoformat ( data . stop_date ) . replace ( tzinfo = timezone . utc ) xmin , ymin , xmax , ymax = ( lon . min (), lat . min (), lon . max (), lat . max (), ) nrows , ncols = data . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , snodas_assim + \".tmp.tif\" ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () # srs.ImportFromEPSG(4326) srs . SetWellKnownGeogCS ( crs . horizontal_datum ) raster . SetProjection ( srs . ExportToWkt ()) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs data_vals = numpy . flipud ( data_vals ) band . WriteArray ( data_vals ) raster . FlushCache () raster = None cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_ ), tmptif , noData = data . no_data_value , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) # Append dictionary object to outfile list outfile_list . append ( { \"filetype\" : \"nohrsc-snodas-swe-corrections\" , \"file\" : tif , \"datetime\" : valid_time . isoformat (), \"version\" : None , } ) logger . debug ( f \"Outfile Append: { outfile_list [ - 1 ] } \" ) break except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-ppt-stable--prism-climate-group","text":"Daily (D2) total precipitation (ppt)(rain+melted snow) Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf","title":"PRISM Climate Group"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-ppt-stable.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-ppt-stable.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-ppt-stable.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.nohrsc-snodas-unmasked--nohrsc-snodas-unmasked","text":"","title":"NOHRSC SNODAS Unmasked"},{"location":"processors/processors/#cumulus_geoproc.processors.nohrsc-snodas-unmasked.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.nohrsc-snodas-unmasked.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nohrsc-snodas-unmasked.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] paramater_codes = [ \"1034\" , \"1036\" , \"1038\" , \"1044\" ] try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) # decompress the tar and gzip files in the tar decompressed_files = utils . decompress ( src , dst , recursive = True ) if not os . path . isdir ( decompressed_files ): raise Exception ( f \"Not a directory: { decompressed_files } \" ) # generator for only the files ending with .txt txt_files = ( f for f in os . listdir ( decompressed_files ) if f . endswith ( \".txt\" )) translate_to_tif = {} # create tif files for only the files needed for txt_file in txt_files : snodas_product_code = txt_file [ 8 : 12 ] if snodas_product_code in paramater_codes : fqpn = os . path . join ( decompressed_files , txt_file ) meta_ntuple = metaparse . to_namedtuple ( fqpn ) data_filename = meta_ntuple . data_file_pathname region = txt_file [: 2 ] stop_date = datetime ( meta_ntuple . stop_year , meta_ntuple . stop_month , meta_ntuple . stop_day , # Metadata value `Stop hour: 5` present in earlier SNODAS files results in incorrect timestamp if used directly as the timestamp for the data # This has since been corrected in the SNODAS metadata .txt files. `Stop hour: 5` is no longer present in current files as of today (2022-08-08) # Additional Information: https://github.com/USACE/cumulus/issues/264, https://github.com/USACE/cumulus/issues/244#issuecomment-1209465407 meta_ntuple . stop_hour if meta_ntuple . stop_year >= 2022 else 6 , meta_ntuple . stop_minute , meta_ntuple . stop_second , tzinfo = timezone . utc , ) # FQPN to data file datafile_pathname = os . path . join ( decompressed_files , data_filename ) logger . debug ( f \"Data File Path: { datafile_pathname } \" ) # write hdr so gdal can tranlate hdr_file = metaparse . write_hdr ( fqpn , meta_ntuple . number_of_columns , meta_ntuple . number_of_rows ) # translate to tif if hdr_file is not None : # set translate options ds = gdal . Open ( datafile_pathname ) cgdal . gdal_translate_options ( tif := file_extension ( datafile_pathname , suffix = \".tif\" ), ds , outputSRS = f \"+proj=longlat +ellps= { meta_ntuple . horizontal_datum } +datum= { meta_ntuple . horizontal_datum } +no_defs\" , noData = int ( meta_ntuple . no_data_value ), outputBounds = [ meta_ntuple . minimum_x_axis_coordinate , meta_ntuple . maximum_y_axis_coordinate , meta_ntuple . maximum_x_axis_coordinate , meta_ntuple . minimum_y_axis_coordinate , ], ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) ds = None # add tif dictionary to compute cold content translate_to_tif [ snodas_product_code ] = { \"file\" : tif , \"filetype\" : snodas . product_code [ snodas_product_code ][ \"product\" ], \"datetime\" : stop_date . isoformat (), \"version\" : None , } logger . debug ( f \"Update Tif: { translate_to_tif [ snodas_product_code ] } \" ) # cold content = swe * 2114 * snowtemp (degc) / 333000 # id 2072 if result := snodas . cold_content ( translate_to_tif ): translate_to_tif . update ( result ) logger . debug ( f \"Cold content product computed and dictionary updated\" ) # convert snow melt to mm if result := snodas . snow_melt_mm ( translate_to_tif ): translate_to_tif . update ( result ) # remove snowmelt with unit meters and scale factor 100_000 _ = translate_to_tif . pop ( \"1044\" , None ) logger . debug ( f \"Snow melt product conversion and original popped from dictionary\" ) outfile_list . extend ( list ( translate_to_tif . values ())) except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-ppt-early--prism-climate-group","text":"Daily (D2) total precipitation (ppt)(rain+melted snow) Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf","title":"PRISM Climate Group"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-ppt-early.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-ppt-early.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-ppt-early.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ndgd-ltia98-airtemp--ndgd-leia98-precipitation","text":"","title":"NDGD LEIA98 Precipitation"},{"location":"processors/processors/#cumulus_geoproc.processors.ndgd-ltia98-airtemp.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ndgd-ltia98-airtemp.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndgd-ltia98-airtemp.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = {} filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list NAEFS Mean 6 hour","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.naefs-mean-06h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.naefs-mean-06h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/naefs-mean-06h.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) products = { \"QPF\" : \"naefs-mean-qpf-06h\" , \"QTF\" : \"naefs-mean-qtf-06h\" } with Dataset ( src , \"r\" ) as ncds : time_str = re . match ( r \"\\d {4} -\\d {2} -\\d {2} \\d+:\\d+:\\d+\" , ncds . date_created ) date_created = datetime . fromisoformat ( time_str [ 0 ]) . replace ( tzinfo = timezone . utc ) lat = ncds . variables [ \"y\" ][:] lon = ncds . variables [ \"x\" ][:] xmin , ymin , xmax , ymax = lon . min (), lat . min (), lon . max (), lat . max () wkt = ncds . variables [ \"crs\" ] . crs_wkt logger . debug ( f \"WKT: { wkt } \" ) nctime = ncds . variables [ \"time\" ] for k , acquirable_ in products . items (): logger . debug ( f \"Product Variable: { k } \" ) logger . debug ( f \"Product Acquirable: { acquirable_ } \" ) ncvar = ncds . variables [ k ] nodata = ncvar . _FillValue _ , nrows , ncols = ncvar . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) _data = None for dt in num2date ( nctime [:], nctime . units , only_use_cftime_datetimes = False ): dt_valid = dt . replace ( tzinfo = timezone . utc ) idx = date2index ( dt , nctime ) nctime_str = datetime . strftime ( dt , \"%Y%m %d %H%M\" ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , filename . replace ( \".nc\" , f \"- { k } - { nctime_str } -tmp.tif\" ) ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () srs . ImportFromWkt ( wkt ) raster . SetProjection ( wkt ) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs _data = ncvar [ idx ] _data = numpy . flipud ( _data ) band . WriteArray ( _data ) raster . FlushCache () raster = None cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , tmptif . replace ( \"-tmp.tif\" , \".tif\" )), tmptif , noData = nodata , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : acquirable_ , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : date_created . isoformat (), } ) except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : raster = None return outfile_list Middle Atlantic River Forecast Center National Blend of Models Surface Temperature 3 hour","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-nbmt-03h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-nbmt-03h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-nbmt-03h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p2-carib--mrms-multisensor-qpe-01h-pass2-carib","text":"","title":"MRMS MultiSensor QPE 01H Pass2 Carib"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p2-carib.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p2-carib.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p2-carib.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass2\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list Middle Atlantic River Forecast Center Real Time Mesoscale Analysis Surface Temperature as Observed","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-rtmat-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-rtmat-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-rtmat-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # closing the data source ds = None raster = None outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-rtmat-01h--north-central-river-forecast-center","text":"Multisensor Precipitation Estimates (MPE)","title":"North Central River Forecast Center"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-rtmat-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-rtmat-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncrfc-rtmat-01h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list Middle Atlantic River Forecast Center National Blend of Models Surface Temperature 1 hour","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-nbmt-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-nbmt-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-nbmt-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-fmat-01h--north-central-river-forecast-center","text":"Forecast Mesoscale Analysis Surface Temperature 01Hr","title":"North Central River Forecast Center"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-fmat-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncrfc-fmat-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncrfc-fmat-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : if dst is None : dst = os . path . dirname ( src ) for grib in gdal . ReadDir ( f \"/vsitar/ { src } \" ): try : filename = utils . file_extension ( grib , suffix = \".tif\" ) ds = gdal . Open ( f \"/vsitar/ { src } / { grib } \" ) raster = ds . GetRasterBand ( 1 ) # Compile regex to get times from timestamp time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) valid_time = ( datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) . isoformat () if valid_time_match else None ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) ref_time = ( datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) . isoformat () if ref_time_match else None ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename ), ds , ) # Append dictionary object to outfile list outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : valid_time , \"version\" : ref_time , } ) except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.nsidc-ua-swe-sd-v1--nsidc-swe-v1","text":"","title":"NSIDC SWE v1"},{"location":"processors/processors/#cumulus_geoproc.processors.nsidc-ua-swe-sd-v1.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.nsidc-ua-swe-sd-v1.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/nsidc-ua-swe-sd-v1.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] # Variables and their product slug nc_variables = { \"SWE\" : \"nsidc-ua-swe-v1\" , \"DEPTH\" : \"nsidc-ua-snowdepth-v1\" , } try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) for nc_variable , nc_slug in nc_variables . items (): ds = gdal . Open ( f \"NETCDF: { src } : { nc_variable } \" ) # set the start time time_pattern = re . compile ( r \"\\w+ \\w+ (\\d {4} -\\d {2} -\\d {2} )\" ) day_since_str = time_pattern . match ( ds . GetMetadataItem ( \"time#units\" )) day_since = datetime . fromisoformat ( day_since_str [ 1 ]) . replace ( tzinfo = timezone . utc ) for band_number in range ( 1 , ds . RasterCount + 1 ): # set the bands date raster = ds . GetRasterBand ( band_number ) delta_days = raster . GetMetadataItem ( \"NETCDF_DIM_time\" ) band_date = day_since + timedelta ( days = int ( delta_days )) datetime_str = band_date . strftime ( \"%Y%m %d \" ) filename_ = utils . file_extension ( filename , suffix = f \"_ { datetime_str } _ { nc_variable } .tif\" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_ ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : nc_slug , \"file\" : tif , \"datetime\" : band_date . isoformat (), \"version\" : None , } ) except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.wpc-qpf-2p5km--wpc-qpf-25km","text":"","title":"WPC QPF 2.5km"},{"location":"processors/processors/#cumulus_geoproc.processors.wpc-qpf-2p5km.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.wpc-qpf-2p5km.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/wpc-qpf-2p5km.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP06\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmin-stable--prism-climate-group","text":"Daily minimum temperature [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf","title":"PRISM Climate Group"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmin-stable.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmin-stable.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmin-stable.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) # closing the data source ds = None outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ndgd-leia98-precip--ndgd-leia98-precipitation","text":"","title":"NDGD LEIA98 Precipitation"},{"location":"processors/processors/#cumulus_geoproc.processors.ndgd-leia98-precip.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ndgd-leia98-precip.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndgd-leia98-precip.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = {} filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.wrf-columbia-airtemp--wrf-columbia-airtemp","text":"","title":"WRF Columbia Airtemp"},{"location":"processors/processors/#cumulus_geoproc.processors.wrf-columbia-airtemp.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.wrf-columbia-airtemp.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/wrf-columbia-airtemp.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] ncds = None try : # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ncds = Dataset ( src , \"r\" ) lon = ncds . variables [ \"lon\" ][:] lat = ncds . variables [ \"lat\" ][:] var = ncds . variables [ \"var\" ][:] time_ = ncds . variables [ \"time\" ] time_pattern = re . compile ( r \"\\w+ \\w+ (\\d {4} -\\d {2} -\\d {2} \\d+:\\d+:\\d+)\" ) time_str = time_pattern . match ( time_ . units ) since_time = datetime . fromisoformat ( time_str [ 1 ]) . replace ( tzinfo = timezone . utc ) nctimes = ( since_time + timedelta ( hours = int ( td )) for td in time_ ) xmin , ymin , xmax , ymax = lon . min (), lat . min (), lon . max (), lat . max () for i , nctime in enumerate ( nctimes ): bandx = var [ i ] nctime_str = datetime . strftime ( nctime , \"%Y_%m_ %d _T%H_%M\" ) nrows , ncols = bandx . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tmp.tif\" ) ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () srs . ImportFromEPSG ( 4326 ) raster . SetProjection ( srs . ExportToWkt ()) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs bandx = numpy . flipud ( bandx ) band . WriteArray ( bandx ) raster . FlushCache () raster = None cgdal . gdal_translate_w_overviews ( tif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tif\" )), tmptif , translate_options = { \"format\" : \"COG\" , \"bandList\" : [ 1 ], \"outputBounds\" : [ - 337997.806 , 812645.371 , 854002.194 , - 535354.629 ], \"outputSRS\" : \"+proj=lcc +lat_1=45 +lat_2=45 +lon_0=-120 +lat_0=45.80369 +x_0=0 +y_0=0 +a=6370000 +b=6370000 +units=m\" , \"creationOptions\" : [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], }, ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) try : os . remove ( tmptif ) except OSError as ex : print ( ex ) outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : nctime . isoformat (), \"version\" : datetime . utcnow (), } ) except Exception as ex : print ( ex ) finally : if ncds : ncds . close () raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p2-alaska--mrms-multisensor-qpe-01h-pass2-alaska","text":"","title":"MRMS MultiSensor QPE 01H Pass2 Alaska"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p2-alaska.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p2-alaska.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p2-alaska.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass2\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list Missouri Basin River Forecast Center","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.mbrfc-krf-qpe-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.mbrfc-krf-qpe-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/mbrfc-krf-qpe-01h.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) time_str = raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) valid_time_match = time_pattern . match ( time_str ) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmax-early--prism-climate-group","text":"Daily (D2) maximum temperature (tmax) [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf","title":"PRISM Climate Group"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmax-early.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmax-early.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmax-early.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ndfd-conus-airtemp--ndfd-conus-airtemp","text":"","title":"NDFD CONUS Airtemp"},{"location":"processors/processors/#cumulus_geoproc.processors.ndfd-conus-airtemp.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ndfd-conus-airtemp.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndfd-conus-airtemp.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] # Create a dictionary of time deltas and equivalent filetype f_type_dict = { 3600 : \"ndfd-conus-airtemp-01h\" , 10800 : \"ndfd-conus-airtemp-03h\" , 21600 : \"ndfd-conus-airtemp-06h\" , } try : filename = os . path . basename ( src ) filename_ = utils . file_extension ( filename , suffix = \"\" ) filename_temp = Template ( \"$ {filename} -$ {ymd} .tif\" ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) count = ds . RasterCount time_pattern = re . compile ( r \"\\d+\" ) tdelta2 = timedelta () for band_number in range ( 1 , count + 1 ): try : tdelta1 = tdelta2 raster = ds . GetRasterBand ( band_number ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) vtime = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) rtime = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) forcast_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_FORECAST_SECONDS\" ) ) forcast_time = float ( forcast_time_match [ 0 ]) # Check the time deltas to see if they are consistant tdelta2 = timedelta ( seconds = forcast_time ) tdelta = ( tdelta2 - tdelta1 ) . seconds # Extract Band; Convert to COG if tdelta in f_type_dict : _filename = filename_temp . substitute ( filename = filename_ , ymd = vtime . strftime ( \"%Y%m %d %H%M\" ) ) logger . debug ( f \"New Filename: { _filename } \" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , _filename ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : f_type_dict [ tdelta ], \"file\" : tif , \"datetime\" : vtime . isoformat (), \"version\" : rtime . isoformat (), } ) except ( RuntimeError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : continue except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmax-stable--prism-climate-group","text":"Daily (D2) maximum temperature (tmax) [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf","title":"PRISM Climate Group"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmax-stable.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmax-stable.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmax-stable.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list Lower Mississippi River Forecast Center (LMRFC) Quantitative Precipitation Estimates (QPE) 1 hour","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.lmrfc-qpe-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.lmrfc-qpe-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/lmrfc-qpe-01h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-gaugecorr-qpe-01h--mrms-gauge-corrected","text":"","title":"MRMS Gauge Corrected"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-gaugecorr-qpe-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-gaugecorr-qpe-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-gaugecorr-qpe-01h.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"GaugeCorrected_QPE_01H\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.serfc-qpe-01h--south-east-river-forecast-center","text":"Quantitative Precipitation Estimates (QPE) 1 hour","title":"South East River Forecast Center"},{"location":"processors/processors/#cumulus_geoproc.processors.serfc-qpe-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.serfc-qpe-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/serfc-qpe-01h.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ()( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ndfd-conus-qpf-06h--ndfd-conus-qpf-6-hour","text":"","title":"NDFD CONUS QPF 6 hour"},{"location":"processors/processors/#cumulus_geoproc.processors.ndfd-conus-qpf-06h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ndfd-conus-qpf-06h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ndfd-conus-qpf-06h.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : filename = os . path . basename ( src ) filename_ = utils . file_extension ( filename , suffix = \"\" ) filename_temp = Template ( \"$ {filename} -$ {ymd} .tif\" ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) count = ds . RasterCount time_pattern = re . compile ( r \"\\d+\" ) for band_number in range ( 1 , count + 1 ): try : raster = ds . GetRasterBand ( band_number ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" ) ) vtime = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" ) ) rtime = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) _filename = filename_temp . substitute ( filename = filename_ , ymd = vtime . strftime ( \"%Y%m %d %H%M\" ) ) logger . debug ( f \"New Filename: { _filename } \" ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , _filename ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : vtime . isoformat (), \"version\" : rtime . isoformat (), } ) except ( RuntimeError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : continue except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list Middle Atlantic River Forecast Center (MARFC) Forecast Mesoscale Analysis Temperature, Air 6 hour","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-fmat-06h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.marfc-fmat-06h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/marfc-fmat-06h.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p1-alaska--mrms-multisensor-qpe-01h-pass1-alaska","text":"","title":"MRMS MultiSensor QPE 01H Pass1 Alaska"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p1-alaska.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p1-alaska.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p1-alaska.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass1\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.hrrr-total-precip--high-resolution-rapid-refresh-hrrr-total-precipitation","text":"","title":"High Resolution Rapid Refresh (HRRR) Total Precipitation"},{"location":"processors/processors/#cumulus_geoproc.processors.hrrr-total-precip--hrrr-file-source","text":"https://nomads.ncep.noaa.gov/pub/data/nccf/com/hrrr/prod/","title":"HRRR file source:"},{"location":"processors/processors/#cumulus_geoproc.processors.hrrr-total-precip--2022-04-29-update","text":"HRRR index files (hrrr_filename.grib2.idx) are used to determine the ever changing '01 hr Total Precipitation' raster band number. Archived HRRR products do not have idx files saved in S3, so this processor tries to account for that.","title":"2022-04-29 Update:"},{"location":"processors/processors/#cumulus_geoproc.processors.hrrr-total-precip.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.hrrr-total-precip.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/hrrr-total-precip.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" , \"GRIB_COMMENT\" : \"precipitation\" , \"GRIB_UNIT\" : \"[kg/(m^2)]\" , } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) # open the hrrr.grib2 file ds = gdal . Open ( src ) # Can't use index file with product downloaded by handler # Successful download means we have the idx we need # idx_file = key + \".idx\" # if hrrridx := boto.s3_download_file(bucket=bucket, key=idx_file, dst=dst): # idx = hrrr.HrrrIdx() # with open(hrrridx, \"r\") as fh: # for line in fh.readlines(): # idx.linex(line) # # This if statement means Total Precip for 01 hr forecast # if idx.element == \"APCP\" and ( # idx.forecast_hour == 0 or idx.forecast_hour == -1 # ): # band_number = idx.raster_band # if band_number is None: # raise Exception(\"Band number not found in idx: {hrrridx}\") # logger.debug(f\"Band number '{band_number}' found in {hrrridx}\") # else: # if (band_number := cgdal.find_band(ds, attr)) is None: # raise Exception(f\"Band number not found for attributes: {attr}\") # print(f\"Band number '{band_number}' found for attributes {attr}\") if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( f \"Band number not found for attributes: { attr } \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.wrf-columbia-precip--wrf-columbia-precipitation","text":"","title":"WRF Columbia Precipitation"},{"location":"processors/processors/#cumulus_geoproc.processors.wrf-columbia-precip.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.wrf-columbia-precip.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/wrf-columbia-precip.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] ncds = None try : # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ncds = Dataset ( src , \"r\" ) lon = ncds . variables [ \"lon\" ][:] lat = ncds . variables [ \"lat\" ][:] var = ncds . variables [ \"var\" ][:] time_ = ncds . variables [ \"time\" ] time_pattern = re . compile ( r \"\\w+ \\w+ (\\d {4} -\\d {2} -\\d {2} \\d+:\\d+:\\d+)\" ) time_str = time_pattern . match ( time_ . units ) since_time = datetime . fromisoformat ( time_str [ 1 ]) . replace ( tzinfo = timezone . utc ) nctimes = ( since_time + timedelta ( hours = int ( td )) for td in time_ ) xmin , ymin , xmax , ymax = lon . min (), lat . min (), lon . max (), lat . max () for i , nctime in enumerate ( nctimes ): bandx = var [ i ] nctime_str = datetime . strftime ( nctime , \"%Y_%m_ %d _T%H_%M\" ) nrows , ncols = bandx . shape xres = ( xmax - xmin ) / float ( ncols ) yres = ( ymax - ymin ) / float ( nrows ) geotransform = ( xmin , xres , 0 , ymax , 0 , - yres ) raster = gdal . GetDriverByName ( \"GTiff\" ) . Create ( tmptif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tmp.tif\" ) ), xsize = ncols , ysize = nrows , bands = 1 , eType = gdal . GDT_Float32 , ) raster . SetGeoTransform ( geotransform ) srs = osr . SpatialReference () srs . ImportFromEPSG ( 4326 ) raster . SetProjection ( srs . ExportToWkt ()) band = raster . GetRasterBand ( 1 ) # Reference the following for reason to flip # https://www.unidata.ucar.edu/support/help/MailArchives/netcdf/msg03585.html # Basically, get the array sequence like other Tiffs bandx = numpy . flipud ( bandx ) band . WriteArray ( bandx ) raster . FlushCache () raster = None cgdal . gdal_translate_w_overviews ( tif := os . path . join ( dst , src . replace ( \".nc\" , f \"- { nctime_str } .tif\" )), tmptif , translate_options = { \"format\" : \"COG\" , \"bandList\" : [ 1 ], \"outputBounds\" : [ - 337997.806 , 812645.371 , 854002.194 , - 535354.629 ], \"outputSRS\" : \"+proj=lcc +lat_1=45 +lat_2=45 +lon_0=-120 +lat_0=45.80369 +x_0=0 +y_0=0 +a=6370000 +b=6370000 +units=m\" , \"creationOptions\" : [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , \"NUM_THREADS=ALL_CPUS\" , ], }, ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) try : os . remove ( tmptif ) except OSError as ex : print ( ex ) outfile_list . append ( { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : nctime . isoformat (), \"version\" : datetime . utcnow (), } ) except Exception as ex : print ( ex ) finally : if ncds : ncds . close () raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmin-early--prism-climate-group","text":"Daily minimum temperature [averaged over all days in the month] Reference: https://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf","title":"PRISM Climate Group"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmin-early.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.prism-tmin-early.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/prism-tmin-early.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = list () try : filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) file_ = utils . decompress ( src , dst ) logger . debug ( f \"Extract from zip: { file_ } \" ) # get date from filename like PRISM_ppt_early_4kmD2_yyyyMMdd_bil.zip time_pattern = re . compile ( r \"\\w+_(?P<ymd>\\d+)_\\w+\" ) m = time_pattern . match ( filename ) dt_valid = datetime . strptime ( m . group ( \"ymd\" ), \"%Y%m %d \" ) . replace ( hour = 12 , minute = 0 , second = 0 , tzinfo = timezone . utc ) src_bil = os . path . join ( file_ , utils . file_extension ( filename , suffix = \".bil\" )) ds = gdal . Open ( src_bil ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) # closing the data source ds = None outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError , IndexError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None return outfile_list Missouri Basin River Forecast Center","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.mbrfc-krf-fct-airtemp-01h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.mbrfc-krf-fct-airtemp-01h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/mbrfc-krf-fct-airtemp-01h.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"TMP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-multisensor-qpe-01h-pass2--mrms-multisensor-qpe-01h-pass2","text":"","title":"MRMS MultiSensor QPE 01H Pass2"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-multisensor-qpe-01h-pass2.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-multisensor-qpe-01h-pass2.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-multisensor-qpe-01h-pass2.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass2\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p1-carib--mrms-multisensor-qpe-01h-pass1-carib","text":"","title":"MRMS MultiSensor QPE 01H Pass1 Carib"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p1-carib.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.ncep-mrms-v12-msqpe01h-p1-carib.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/ncep-mrms-v12-msqpe01h-p1-carib.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"MultiSensor_QPE_01H_Pass1\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) # validate COG if ( validate := cgdal . validate_cog ( \"-q\" , tif )) == 0 : logger . debug ( f \"Validate COG = { validate } \\t { tif } is a COG\" ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : None , }, ] except ( RuntimeError , KeyError ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : # closing the data source ds = None raster = None return outfile_list Missouri Basin River Forecast Center","title":"Grid processor"},{"location":"processors/processors/#cumulus_geoproc.processors.mbrfc-krf-qpf-06h.process","text":"","title":"process()"},{"location":"processors/processors/#cumulus_geoproc.processors.mbrfc-krf-qpf-06h.process--grid-processor","text":"Requires keyword only arguments (*) Parameters: Name Type Description Default src str path to input file for processing required dst str , optional path to temporary directory None acquirable str acquirable slug None Returns: Type Description List [ dict ] \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone Source code in cumulus_geoproc/processors/mbrfc-krf-qpf-06h.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 @pyplugs . register def process ( * , src : str , dst : str = None , acquirable : str = None ): \"\"\" # Grid processor __Requires keyword only arguments (*)__ Parameters ---------- src : str path to input file for processing dst : str, optional path to temporary directory acquirable: str, optional acquirable slug Returns ------- List[dict] ``` { \"filetype\": str, Matching database acquirable \"file\": str, Converted file \"datetime\": str, Valid Time, ISO format with timezone \"version\": str Reference Time (forecast), ISO format with timezone } ``` \"\"\" outfile_list = [] try : attr = { \"GRIB_ELEMENT\" : \"APCP\" } filename = os . path . basename ( src ) filename_dst = utils . file_extension ( filename ) # Take the source path as the destination unless defined. # User defined `dst` not programatically removed unless under # source's temporary directory. if dst is None : dst = os . path . dirname ( src ) ds = gdal . Open ( \"/vsigzip/\" + src ) if ( band_number := cgdal . find_band ( ds , attr )) is None : raise Exception ( \"Band number not found for attributes: {attr} \" ) logger . debug ( f \"Band number ' { band_number } ' found for attributes { attr } \" ) raster = ds . GetRasterBand ( band_number ) # Get Datetime from String Like \"1599008400 sec UTC\" time_pattern = re . compile ( r \"\\d+\" ) valid_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_VALID_TIME\" )) dt_valid = datetime . fromtimestamp ( int ( valid_time_match [ 0 ]), timezone . utc ) ref_time_match = time_pattern . match ( raster . GetMetadataItem ( \"GRIB_REF_TIME\" )) dt_ref = datetime . fromtimestamp ( int ( ref_time_match [ 0 ]), timezone . utc ) cgdal . gdal_translate_w_options ( tif := os . path . join ( dst , filename_dst ), ds , ) outfile_list = [ { \"filetype\" : acquirable , \"file\" : tif , \"datetime\" : dt_valid . isoformat (), \"version\" : dt_ref . isoformat (), }, ] except ( RuntimeError , KeyError , Exception ) as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : ds = None raster = None return outfile_list","title":"Grid processor"},{"location":"utils/boto/","text":"Cumulus utilities helping with S3 functionality boto3_client ( ** kwargs ) Define boto3 client Returns: Type Description boto3 . client client object with default options with or without user defined attributes Source code in cumulus_geoproc/utils/boto.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def boto3_client ( ** kwargs ): \"\"\"Define boto3 client Returns ------- boto3.client client object with default options with or without user defined attributes \"\"\" kwargs_ = { \"aws_access_key_id\" : AWS_ACCESS_KEY_ID , \"aws_secret_access_key\" : AWS_SECRET_ACCESS_KEY , \"region_name\" : AWS_DEFAULT_REGION , ** kwargs , } return boto3 . client ( ** kwargs_ ) boto3_resource ( ** kwargs ) Define boto3 resource Returns: Type Description boto3 . resource resource object with default options with or without user defined attributes Source code in cumulus_geoproc/utils/boto.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def boto3_resource ( ** kwargs ): \"\"\"Define boto3 resource Returns ------- boto3.resource resource object with default options with or without user defined attributes \"\"\" kwargs_ = { \"aws_access_key_id\" : AWS_ACCESS_KEY_ID , \"aws_secret_access_key\" : AWS_SECRET_ACCESS_KEY , \"region_name\" : AWS_DEFAULT_REGION , ** kwargs , } return boto3 . resource ( ** kwargs_ ) s3_download_file ( bucket , key , dst = '/tmp' , prefix = None ) Wrapper supporting S3 downloading a file Parameters: Name Type Description Default bucket str S3 Bucket required key str S3 key object required prefix str , optional Add prefix to filename, by default \"\" None dst str , optional FQP to temporary directory, by default \"/tmp\" '/tmp' Returns: Type Description str | False FQPN to downloaded file | False if failed Raises: Type Description Exception ClientError Source code in cumulus_geoproc/utils/boto.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def s3_download_file ( bucket : str , key : str , dst : str = \"/tmp\" , prefix : str = None ): \"\"\"Wrapper supporting S3 downloading a file Parameters ---------- bucket : str S3 Bucket key : str S3 key object prefix : str, optional Add prefix to filename, by default \"\" dst : str, optional FQP to temporary directory, by default \"/tmp\" Returns ------- str | False FQPN to downloaded file | False if failed Raises ------ Exception ClientError \"\"\" file = os . path . basename ( key ) file = prefix + \"-\" + file if prefix else file filename = os . path . join ( dst , file ) logger . debug ( f \"S3 Download File: { filename } \" ) # download the file try : if ( s3 := boto3_resource ( service_name = \"s3\" , endpoint_url = ENDPOINT_URL_S3 , ) ) is None : raise Exception ( ClientError ) s3 . meta . client . download_file ( Bucket = bucket , Key = key , Filename = filename , ) except ClientError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } - key: { key } \" ) return return filename s3_upload_file ( file_name , bucket , key = None ) Wrapper supporting S3 uploading a file Parameters: Name Type Description Default file_name str file to upload required bucket str S3 bucket required key str , optional S3 object key, by default None None Returns: Type Description bool boolean describing successful upload Raises: Type Description Exception ClientError Source code in cumulus_geoproc/utils/boto.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def s3_upload_file ( file_name : str , bucket : str , key : str = None ): \"\"\"Wrapper supporting S3 uploading a file Parameters ---------- file_name : str file to upload bucket : str S3 bucket key : str, optional S3 object key, by default None Returns ------- bool boolean describing successful upload Raises ------ Exception ClientError \"\"\" # If S3 object_name was not specified, use file_name if key is None : key = os . path . basename ( file_name ) # Upload the file try : if ( s3 := boto3_resource ( service_name = \"s3\" , endpoint_url = ENDPOINT_URL_S3 , ) ) is None : raise Exception ( ClientError ) s3 . meta . client . upload_file ( Filename = file_name , Bucket = bucket , Key = key ) logger . debug ( f \" { file_name } \\t { bucket =} \\t { key =} \" ) except ClientError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } - key: { key } \" ) return False return True","title":"Boto"},{"location":"utils/boto/#cumulus_geoproc.utils.boto.boto3_client","text":"Define boto3 client Returns: Type Description boto3 . client client object with default options with or without user defined attributes Source code in cumulus_geoproc/utils/boto.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def boto3_client ( ** kwargs ): \"\"\"Define boto3 client Returns ------- boto3.client client object with default options with or without user defined attributes \"\"\" kwargs_ = { \"aws_access_key_id\" : AWS_ACCESS_KEY_ID , \"aws_secret_access_key\" : AWS_SECRET_ACCESS_KEY , \"region_name\" : AWS_DEFAULT_REGION , ** kwargs , } return boto3 . client ( ** kwargs_ )","title":"boto3_client()"},{"location":"utils/boto/#cumulus_geoproc.utils.boto.boto3_resource","text":"Define boto3 resource Returns: Type Description boto3 . resource resource object with default options with or without user defined attributes Source code in cumulus_geoproc/utils/boto.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def boto3_resource ( ** kwargs ): \"\"\"Define boto3 resource Returns ------- boto3.resource resource object with default options with or without user defined attributes \"\"\" kwargs_ = { \"aws_access_key_id\" : AWS_ACCESS_KEY_ID , \"aws_secret_access_key\" : AWS_SECRET_ACCESS_KEY , \"region_name\" : AWS_DEFAULT_REGION , ** kwargs , } return boto3 . resource ( ** kwargs_ )","title":"boto3_resource()"},{"location":"utils/boto/#cumulus_geoproc.utils.boto.s3_download_file","text":"Wrapper supporting S3 downloading a file Parameters: Name Type Description Default bucket str S3 Bucket required key str S3 key object required prefix str , optional Add prefix to filename, by default \"\" None dst str , optional FQP to temporary directory, by default \"/tmp\" '/tmp' Returns: Type Description str | False FQPN to downloaded file | False if failed Raises: Type Description Exception ClientError Source code in cumulus_geoproc/utils/boto.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def s3_download_file ( bucket : str , key : str , dst : str = \"/tmp\" , prefix : str = None ): \"\"\"Wrapper supporting S3 downloading a file Parameters ---------- bucket : str S3 Bucket key : str S3 key object prefix : str, optional Add prefix to filename, by default \"\" dst : str, optional FQP to temporary directory, by default \"/tmp\" Returns ------- str | False FQPN to downloaded file | False if failed Raises ------ Exception ClientError \"\"\" file = os . path . basename ( key ) file = prefix + \"-\" + file if prefix else file filename = os . path . join ( dst , file ) logger . debug ( f \"S3 Download File: { filename } \" ) # download the file try : if ( s3 := boto3_resource ( service_name = \"s3\" , endpoint_url = ENDPOINT_URL_S3 , ) ) is None : raise Exception ( ClientError ) s3 . meta . client . download_file ( Bucket = bucket , Key = key , Filename = filename , ) except ClientError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } - key: { key } \" ) return return filename","title":"s3_download_file()"},{"location":"utils/boto/#cumulus_geoproc.utils.boto.s3_upload_file","text":"Wrapper supporting S3 uploading a file Parameters: Name Type Description Default file_name str file to upload required bucket str S3 bucket required key str , optional S3 object key, by default None None Returns: Type Description bool boolean describing successful upload Raises: Type Description Exception ClientError Source code in cumulus_geoproc/utils/boto.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def s3_upload_file ( file_name : str , bucket : str , key : str = None ): \"\"\"Wrapper supporting S3 uploading a file Parameters ---------- file_name : str file to upload bucket : str S3 bucket key : str, optional S3 object key, by default None Returns ------- bool boolean describing successful upload Raises ------ Exception ClientError \"\"\" # If S3 object_name was not specified, use file_name if key is None : key = os . path . basename ( file_name ) # Upload the file try : if ( s3 := boto3_resource ( service_name = \"s3\" , endpoint_url = ENDPOINT_URL_S3 , ) ) is None : raise Exception ( ClientError ) s3 . meta . client . upload_file ( Filename = file_name , Bucket = bucket , Key = key ) logger . debug ( f \" { file_name } \\t { bucket =} \\t { key =} \" ) except ClientError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } - key: { key } \" ) return False return True","title":"s3_upload_file()"},{"location":"utils/capi/","text":"Cumulus geoprocessor utilities CumulusAPI Cumulus API class providing functionality to make requests asyncio implemented with httpx for HTTP/2 protocol Source code in cumulus_geoproc/utils/capi.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class CumulusAPI : \"\"\"Cumulus API class providing functionality to make requests asyncio implemented with httpx for HTTP/2 protocol \"\"\" def __init__ ( self , url : str , http2 : bool = False ): # set url to env var if not provided self . url = url self . http2 = http2 self . url_split = urlsplit ( self . url ) . _asdict () def __repr__ ( self ) -> str : return f \" { __class__ . __name__ } ( { self . url } , { self . http2 } , { self . url_split } )\" @property def parameters ( self ): return self . url_split @parameters . setter def parameters ( self , key_val ): self . url_split [ key_val [ 0 ]] = key_val [ 1 ] self . build_url ( self . url_split ) def build_url ( self , url_params ): self . url = urlunsplit ( namedtuple ( \"UrlUnsplit\" , url_params . keys ())( ** url_params )) @property def endpoint ( self ): return self . url_split [ \"path\" ] @endpoint . setter def endpoint ( self , endpoint ): self . url_split [ \"path\" ] = endpoint self . build_url ( self . url_split ) @property def query ( self ): return self . url_split [ \"query\" ] @query . setter def query ( self , query : dict ): self . url_split [ \"query\" ] = urlencode ( query ) self . build_url ( self . url_split ) async def post_ ( self , url , payload ): try : client = httpx . AsyncClient ( http2 = self . http2 ) headers = [( b \"content-type\" , b \"application/json\" )] resp = await client . post ( url , headers = headers , json = payload ) if resp . status_code in ( 200 , 201 ): return resp . json () except ConnectionError as ex : logger . warning ( ex ) async def put_ ( self , url , payload ): try : client = httpx . AsyncClient ( http2 = self . http2 ) headers = [( b \"content-type\" , b \"application/json\" )] resp = await client . put ( url , headers = headers , json = payload ) if resp . status_code in ( 200 , 201 ): return resp . json () except ConnectionError as ex : logger . warning ( ex ) async def get_ ( self , url ): try : async with httpx . AsyncClient ( http2 = self . http2 ) as client : resp = await client . get ( url ) if resp . status_code == 200 : return resp except ConnectionError as ex : logger . warning ( ex ) NotifyCumulus Bases: CumulusAPI Cumulus notification class extending CumulusAPI Parameters: Name Type Description Default CumulusAPI class base class required Source code in cumulus_geoproc/utils/capi.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class NotifyCumulus ( CumulusAPI ): \"\"\"Cumulus notification class extending CumulusAPI Parameters ---------- CumulusAPI : class base class \"\"\" def __init__ ( self , url , http2 = True ): super () . __init__ ( url , http2 ) self . endpoint = \"productfiles\" self . query = { \"key\" : APPLICATION_KEY } def run ( self , payload ): self . post ( self . url , payload = payload )","title":"Capi"},{"location":"utils/capi/#cumulus_geoproc.utils.capi.CumulusAPI","text":"Cumulus API class providing functionality to make requests asyncio implemented with httpx for HTTP/2 protocol Source code in cumulus_geoproc/utils/capi.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class CumulusAPI : \"\"\"Cumulus API class providing functionality to make requests asyncio implemented with httpx for HTTP/2 protocol \"\"\" def __init__ ( self , url : str , http2 : bool = False ): # set url to env var if not provided self . url = url self . http2 = http2 self . url_split = urlsplit ( self . url ) . _asdict () def __repr__ ( self ) -> str : return f \" { __class__ . __name__ } ( { self . url } , { self . http2 } , { self . url_split } )\" @property def parameters ( self ): return self . url_split @parameters . setter def parameters ( self , key_val ): self . url_split [ key_val [ 0 ]] = key_val [ 1 ] self . build_url ( self . url_split ) def build_url ( self , url_params ): self . url = urlunsplit ( namedtuple ( \"UrlUnsplit\" , url_params . keys ())( ** url_params )) @property def endpoint ( self ): return self . url_split [ \"path\" ] @endpoint . setter def endpoint ( self , endpoint ): self . url_split [ \"path\" ] = endpoint self . build_url ( self . url_split ) @property def query ( self ): return self . url_split [ \"query\" ] @query . setter def query ( self , query : dict ): self . url_split [ \"query\" ] = urlencode ( query ) self . build_url ( self . url_split ) async def post_ ( self , url , payload ): try : client = httpx . AsyncClient ( http2 = self . http2 ) headers = [( b \"content-type\" , b \"application/json\" )] resp = await client . post ( url , headers = headers , json = payload ) if resp . status_code in ( 200 , 201 ): return resp . json () except ConnectionError as ex : logger . warning ( ex ) async def put_ ( self , url , payload ): try : client = httpx . AsyncClient ( http2 = self . http2 ) headers = [( b \"content-type\" , b \"application/json\" )] resp = await client . put ( url , headers = headers , json = payload ) if resp . status_code in ( 200 , 201 ): return resp . json () except ConnectionError as ex : logger . warning ( ex ) async def get_ ( self , url ): try : async with httpx . AsyncClient ( http2 = self . http2 ) as client : resp = await client . get ( url ) if resp . status_code == 200 : return resp except ConnectionError as ex : logger . warning ( ex )","title":"CumulusAPI"},{"location":"utils/capi/#cumulus_geoproc.utils.capi.NotifyCumulus","text":"Bases: CumulusAPI Cumulus notification class extending CumulusAPI Parameters: Name Type Description Default CumulusAPI class base class required Source code in cumulus_geoproc/utils/capi.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 class NotifyCumulus ( CumulusAPI ): \"\"\"Cumulus notification class extending CumulusAPI Parameters ---------- CumulusAPI : class base class \"\"\" def __init__ ( self , url , http2 = True ): super () . __init__ ( url , http2 ) self . endpoint = \"productfiles\" self . query = { \"key\" : APPLICATION_KEY } def run ( self , payload ): self . post ( self . url , payload = payload )","title":"NotifyCumulus"},{"location":"utils/cgdal/","text":"Cumulus specific gdal utilities GTiff Creation Options to be a COG: \"-co\", \"COMPRESS=LZW\", \"-co\", \"COPY_SRC_OVERVIEWS=YES\", \"-co\", \"TILE=YES\", find_band ( data_set , attr = {}) Return the band number Parameters: Name Type Description Default data_set gdal . Dataset gdal dataset required attr dict , optional attributes matching those in the metadata, by default {} {} Returns: Type Description int band number Source code in cumulus_geoproc/utils/cgdal.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def find_band ( data_set : \"gdal.Dataset\" , attr : dict = {}): \"\"\"Return the band number Parameters ---------- data_set : gdal.Dataset gdal dataset attr : dict, optional attributes matching those in the metadata, by default {} Returns ------- int band number \"\"\" count = data_set . RasterCount for b in range ( 1 , count + 1 ): try : raster = data_set . GetRasterBand ( b ) meta = raster . GetMetadata_Dict () has_attr = [ True for key , val in attr . items () if ( key in meta and val in raster . GetMetadataItem ( key )) ] if len ( has_attr ) == len ( attr ): logger . debug ( f \" { has_attr =} \" ) return b except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue finally : raster = None return None gdal_calculate ( * args ) Implement gdal-utils gdal_calc CLI utility gdal_translate documentation: https://gdal.org/programs/gdal_translate.html Source code in cumulus_geoproc/utils/cgdal.py 202 203 204 205 206 207 208 209 210 211 212 213 214 def gdal_calculate ( * args ): \"\"\"Implement gdal-utils gdal_calc CLI utility gdal_translate documentation: https://gdal.org/programs/gdal_translate.html \"\"\" argv = [ gdal_calc . __file__ ] argv . extend ( list ( args )) logger . debug ( f \"Argvs: { argv =} \" ) gdal_calc . main ( argv ) gdal_fillnodataval ( src , dst , / , * args ) Implement gdal-utils gdal_fillnodata CLI utility as a subprocess gdal_fillnodata documentation: https://gdal.org/programs/gdal_fillnodata.html Source code in cumulus_geoproc/utils/cgdal.py 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def gdal_fillnodataval ( src : str , dst : str , / , * args ): \"\"\"Implement gdal-utils gdal_fillnodata CLI utility as a subprocess gdal_fillnodata documentation: https://gdal.org/programs/gdal_fillnodata.html \"\"\" argv = [ \"gdal_fillnodata.py\" ] argv . extend ( list ( args )) argv . append ( src ) argv . append ( dst ) logger . debug ( f \"Argvs: { argv =} \" ) try : result = subprocess . check_call ( argv , cwd = pathlib . PurePath ( src ) . parent ) return result except subprocess . CalledProcessError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return result gdal_translate_options ( ** kwargs ) Return gdal translate options Add dictionary attributes to use those options for translate Adding an existing attribute in 'base' will overwright that option Returns: Type Description dict dictionary of gdal translate options with base option(s) base = { \"format\": \"COG\", } Source code in cumulus_geoproc/utils/cgdal.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def gdal_translate_options ( ** kwargs ): \"\"\" # Return gdal translate options Add dictionary attributes to use those options for translate Adding an existing attribute in 'base' will overwright that option Returns ------- dict dictionary of gdal translate options with base option(s) base = { \"format\": \"COG\", } \"\"\" # COG driver generates overviews while GTiff uses seperate step to build them base = { \"format\" : \"COG\" , } return { ** base , ** kwargs } gdal_translate_w_options ( dst , src , ** kwargs ) GDAL Translate wrapper with base configurations Parameters: Name Type Description Default dst str Output dataset required src gdal . Dataset Dataset object or a filename required **kwargs User defined keyword arguments {} Source code in cumulus_geoproc/utils/cgdal.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def gdal_translate_w_options ( dst : str , src : gdal . Dataset , ** kwargs , ): \"\"\" # GDAL Translate wrapper with base configurations Parameters ---------- dst : str Output dataset src : gdal.Dataset Dataset object or a filename **kwargs User defined keyword arguments \"\"\" base = { \"format\" : \"COG\" , \"bandList\" : [ 1 ], \"creationOptions\" : [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], } _kwargs = { ** base , ** kwargs } gdal . Translate ( dst , src , ** _kwargs , ) gdal_translate_w_overviews ( dst , src , translate_options , resampling = None , overviewlist = [ 2 , 4 , 8 , 16 , 32 , 64 , 128 , 256 , 512 , 1024 , 2048 ]) Build overviews for the gdal dataset with the resampling algorithm provided If no sampling algorithm is given, only gdal.Translate() executed allowable resampling algorithms: nearest,average,rms,bilinear,gauss,cubic,cubicspline,lanczos,average_magphase,mode Parameters: Name Type Description Default dst str Output dataset name required src gdal . Dataset Dataset object or a filename required translate_options dict Dictionary of creation options required resampling str , optional resampling algorithm, by default None None overviewlist List [ int ], optional list of integers, by default [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] Source code in cumulus_geoproc/utils/cgdal.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def gdal_translate_w_overviews ( dst : str , src : gdal . Dataset , translate_options : dict , resampling : str = None , overviewlist : List [ int ] = [ 2 , 4 , 8 , 16 , 32 , 64 , 128 , 256 , 512 , 1024 , 2048 ], ): \"\"\"Build overviews for the gdal dataset with the resampling algorithm provided If no sampling algorithm is given, only gdal.Translate() executed allowable resampling algorithms: nearest,average,rms,bilinear,gauss,cubic,cubicspline,lanczos,average_magphase,mode Parameters ---------- dst : str Output dataset name src : gdal.Dataset Dataset object or a filename translate_options : dict Dictionary of creation options resampling : str, optional resampling algorithm, by default None overviewlist : List[int], optional list of integers, by default [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] \"\"\" resampling_algo = ( \"nearest\" , \"average\" , \"rms\" , \"bilinear\" , \"gauss\" , \"cubic\" , \"cubicspline\" , \"lanczos\" , \"average_magphase\" , \"mode\" , ) if resampling is not None and resampling not in resampling_algo : logger . debug ( f \"Resampling algorithm { resampling } not available\" ) return False try : if resampling : gdal . Translate ( f \"/vsimem/ { dst } \" , src , format = \"GTiff\" , creationOptions = [ \"COMPRESS=LZW\" , \"TILED=YES\" , ], ) _ds = gdal . Open ( f \"/vsimem/ { dst } \" , gdal . GA_Update ) _ds . BuildOverviews ( resampling = resampling , overviewlist = overviewlist ) gdal . Translate ( dst , _ds , ** translate_options , ) else : gdal . Translate ( dst , src , ** translate_options , ) return True except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : _ds = None return False","title":"Cgdal"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal--cumulus-specific-gdal-utilities","text":"GTiff Creation Options to be a COG: \"-co\", \"COMPRESS=LZW\", \"-co\", \"COPY_SRC_OVERVIEWS=YES\", \"-co\", \"TILE=YES\",","title":"Cumulus specific gdal utilities"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.find_band","text":"Return the band number Parameters: Name Type Description Default data_set gdal . Dataset gdal dataset required attr dict , optional attributes matching those in the metadata, by default {} {} Returns: Type Description int band number Source code in cumulus_geoproc/utils/cgdal.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def find_band ( data_set : \"gdal.Dataset\" , attr : dict = {}): \"\"\"Return the band number Parameters ---------- data_set : gdal.Dataset gdal dataset attr : dict, optional attributes matching those in the metadata, by default {} Returns ------- int band number \"\"\" count = data_set . RasterCount for b in range ( 1 , count + 1 ): try : raster = data_set . GetRasterBand ( b ) meta = raster . GetMetadata_Dict () has_attr = [ True for key , val in attr . items () if ( key in meta and val in raster . GetMetadataItem ( key )) ] if len ( has_attr ) == len ( attr ): logger . debug ( f \" { has_attr =} \" ) return b except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) continue finally : raster = None return None","title":"find_band()"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.gdal_calculate","text":"Implement gdal-utils gdal_calc CLI utility gdal_translate documentation: https://gdal.org/programs/gdal_translate.html Source code in cumulus_geoproc/utils/cgdal.py 202 203 204 205 206 207 208 209 210 211 212 213 214 def gdal_calculate ( * args ): \"\"\"Implement gdal-utils gdal_calc CLI utility gdal_translate documentation: https://gdal.org/programs/gdal_translate.html \"\"\" argv = [ gdal_calc . __file__ ] argv . extend ( list ( args )) logger . debug ( f \"Argvs: { argv =} \" ) gdal_calc . main ( argv )","title":"gdal_calculate()"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.gdal_fillnodataval","text":"Implement gdal-utils gdal_fillnodata CLI utility as a subprocess gdal_fillnodata documentation: https://gdal.org/programs/gdal_fillnodata.html Source code in cumulus_geoproc/utils/cgdal.py 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def gdal_fillnodataval ( src : str , dst : str , / , * args ): \"\"\"Implement gdal-utils gdal_fillnodata CLI utility as a subprocess gdal_fillnodata documentation: https://gdal.org/programs/gdal_fillnodata.html \"\"\" argv = [ \"gdal_fillnodata.py\" ] argv . extend ( list ( args )) argv . append ( src ) argv . append ( dst ) logger . debug ( f \"Argvs: { argv =} \" ) try : result = subprocess . check_call ( argv , cwd = pathlib . PurePath ( src ) . parent ) return result except subprocess . CalledProcessError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) return result","title":"gdal_fillnodataval()"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.gdal_translate_options","text":"","title":"gdal_translate_options()"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.gdal_translate_options--return-gdal-translate-options","text":"Add dictionary attributes to use those options for translate Adding an existing attribute in 'base' will overwright that option Returns: Type Description dict dictionary of gdal translate options with base option(s) base = { \"format\": \"COG\", } Source code in cumulus_geoproc/utils/cgdal.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def gdal_translate_options ( ** kwargs ): \"\"\" # Return gdal translate options Add dictionary attributes to use those options for translate Adding an existing attribute in 'base' will overwright that option Returns ------- dict dictionary of gdal translate options with base option(s) base = { \"format\": \"COG\", } \"\"\" # COG driver generates overviews while GTiff uses seperate step to build them base = { \"format\" : \"COG\" , } return { ** base , ** kwargs }","title":"Return gdal translate options"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.gdal_translate_w_options","text":"","title":"gdal_translate_w_options()"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.gdal_translate_w_options--gdal-translate-wrapper-with-base-configurations","text":"Parameters: Name Type Description Default dst str Output dataset required src gdal . Dataset Dataset object or a filename required **kwargs User defined keyword arguments {} Source code in cumulus_geoproc/utils/cgdal.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def gdal_translate_w_options ( dst : str , src : gdal . Dataset , ** kwargs , ): \"\"\" # GDAL Translate wrapper with base configurations Parameters ---------- dst : str Output dataset src : gdal.Dataset Dataset object or a filename **kwargs User defined keyword arguments \"\"\" base = { \"format\" : \"COG\" , \"bandList\" : [ 1 ], \"creationOptions\" : [ \"RESAMPLING=BILINEAR\" , \"OVERVIEWS=IGNORE_EXISTING\" , \"OVERVIEW_RESAMPLING=BILINEAR\" , ], } _kwargs = { ** base , ** kwargs } gdal . Translate ( dst , src , ** _kwargs , )","title":"GDAL Translate wrapper with base configurations"},{"location":"utils/cgdal/#cumulus_geoproc.utils.cgdal.gdal_translate_w_overviews","text":"Build overviews for the gdal dataset with the resampling algorithm provided If no sampling algorithm is given, only gdal.Translate() executed allowable resampling algorithms: nearest,average,rms,bilinear,gauss,cubic,cubicspline,lanczos,average_magphase,mode Parameters: Name Type Description Default dst str Output dataset name required src gdal . Dataset Dataset object or a filename required translate_options dict Dictionary of creation options required resampling str , optional resampling algorithm, by default None None overviewlist List [ int ], optional list of integers, by default [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] Source code in cumulus_geoproc/utils/cgdal.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def gdal_translate_w_overviews ( dst : str , src : gdal . Dataset , translate_options : dict , resampling : str = None , overviewlist : List [ int ] = [ 2 , 4 , 8 , 16 , 32 , 64 , 128 , 256 , 512 , 1024 , 2048 ], ): \"\"\"Build overviews for the gdal dataset with the resampling algorithm provided If no sampling algorithm is given, only gdal.Translate() executed allowable resampling algorithms: nearest,average,rms,bilinear,gauss,cubic,cubicspline,lanczos,average_magphase,mode Parameters ---------- dst : str Output dataset name src : gdal.Dataset Dataset object or a filename translate_options : dict Dictionary of creation options resampling : str, optional resampling algorithm, by default None overviewlist : List[int], optional list of integers, by default [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048] \"\"\" resampling_algo = ( \"nearest\" , \"average\" , \"rms\" , \"bilinear\" , \"gauss\" , \"cubic\" , \"cubicspline\" , \"lanczos\" , \"average_magphase\" , \"mode\" , ) if resampling is not None and resampling not in resampling_algo : logger . debug ( f \"Resampling algorithm { resampling } not available\" ) return False try : if resampling : gdal . Translate ( f \"/vsimem/ { dst } \" , src , format = \"GTiff\" , creationOptions = [ \"COMPRESS=LZW\" , \"TILED=YES\" , ], ) _ds = gdal . Open ( f \"/vsimem/ { dst } \" , gdal . GA_Update ) _ds . BuildOverviews ( resampling = resampling , overviewlist = overviewlist ) gdal . Translate ( dst , _ds , ** translate_options , ) else : gdal . Translate ( dst , src , ** translate_options , ) return True except RuntimeError as ex : logger . error ( f \" { type ( ex ) . __name__ } : { this } : { ex } \" ) finally : _ds = None return False","title":"gdal_translate_w_overviews()"}]}